{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87297a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://huggingface.co/hfl/llama-3-chinese-8b\n",
    "## https://huggingface.co/hfl/llama-3-chinese-8b/tree/main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b474668-055c-4666-9373-d4633d261380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/HuggingFace自然语言处理\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/HuggingFace自然语言处理\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90307fd-3ced-4ab3-9a5e-20ea112650c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型太大了，直接GG了。\n",
    "## 卧槽了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf9dbbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaa00780236d4456ae47b3582eed6bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text-generation\", \n",
    "    model=create_originalData_path(\"llama-3-chinese-8b/\"), \n",
    "    device = torch.device(\"mps\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718ececa-2f18-4598-9afc-9ae407aba798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "835c934a-8b45-4949-aeb8-40e4277651f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 使用pipeline进行预测  \n",
    "result = pipe(\"这是一个示例文本。\")  \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03d381b-08d8-4045-b1a7-b4e0b348d6b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a14844-c814-46a0-a51e-911a66aea3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc77177-ec43-493f-bcc3-3b021f3a1e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccb3b39-358f-4b4c-8525-e4e905e137f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2aab1ba-fe8e-49b9-9a28-4f974c6376ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

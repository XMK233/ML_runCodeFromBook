{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7911329c-a417-41c6-b707-490cda119196",
   "metadata": {},
   "source": [
    "https://github.com/AI4Finance-Foundation\n",
    "\n",
    "* 如果使用python3.8的话，requirements可以都装上，但是fin-rl库没法安装，因为需要3.11的python。\n",
    "* 如果使用py3.11的话，requirements不能都装上，那就不装了，直接把Fin-RL库的代码下载到本地，进去，然后“pip install .”就好了。\n",
    "* 然后下载FinRL-Meta库代码到本地，工作目录改到其下即可。\n",
    "* 然后就缺啥库补啥库好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78e215e3-b086-404f-a85e-f509e38a255b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 我老妈在家里研究股票。\n",
    "# 挣了钱就过来跟我炫耀：\n",
    "# 是不是比你的时薪还要高。\n",
    "# 我每天卷得像我的裤脚。\n",
    "# 自己的时间太少，每天晚上舍不得睡觉。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "380d52c3-23ce-4fa2-b0c7-fa25de6ee8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/Users/minkexiu/Desktop/FinRL-Meta-master/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8183fb5-4296-442f-8c1f-70955237870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae934f2-97e5-462d-93d8-623926e2ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython import display\n",
    "display.set_matplotlib_formats(\"svg\") ## 设置一下，这样一来，图片就是svg格式的矢量图了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d6205b-82f6-4d3e-ab96-644eb1d0f4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from meta import config\n",
    "from meta.data_processor import DataProcessor\n",
    "from main import check_and_make_directories\n",
    "from meta.data_processors.tushare import Tushare, ReturnPlotter\n",
    "from meta.env_stock_trading.env_stocktrading_China_A_shares import (\n",
    "    StockTradingEnv,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e33a8b-84c3-4bf8-9b0e-fa1a4ec4300b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents.stablebaselines3_models import DRLAgent\n",
    "import os\n",
    "from typing import List\n",
    "from argparse import ArgumentParser\n",
    "from meta import config\n",
    "from meta.config_tickers import DOW_30_TICKER\n",
    "from meta.config import (\n",
    "    DATA_SAVE_DIR,\n",
    "    TRAINED_MODEL_DIR,\n",
    "    TENSORBOARD_LOG_DIR,\n",
    "    RESULTS_DIR,\n",
    "    INDICATORS,\n",
    "    TRAIN_START_DATE,\n",
    "    TRAIN_END_DATE,\n",
    "    TEST_START_DATE,\n",
    "    TEST_END_DATE,\n",
    "    TRADE_START_DATE,\n",
    "    TRADE_END_DATE,\n",
    "    ERL_PARAMS,\n",
    "    RLlib_PARAMS,\n",
    "    SAC_PARAMS,\n",
    "    ALPACA_API_KEY,\n",
    "    ALPACA_API_SECRET,\n",
    "    ALPACA_API_BASE_URL,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6840bef3-9857-4b8a-bf3b-2b9a1e96aa99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL Modules have been imported!\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_columns = None\n",
    "\n",
    "print(\"ALL Modules have been imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94bdebbe-21db-4421-be3a-bc3607d60f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "use check_and_make_directories() to replace the following\n",
    "\n",
    "if not os.path.exists(\"./datasets\"):\n",
    "    os.makedirs(\"./datasets\")\n",
    "if not os.path.exists(\"./trained_models\"):\n",
    "    os.makedirs(\"./trained_models\")\n",
    "if not os.path.exists(\"./tensorboard_log\"):\n",
    "    os.makedirs(\"./tensorboard_log\")\n",
    "if not os.path.exists(\"./results\"):\n",
    "    os.makedirs(\"./results\")\n",
    "\"\"\"\n",
    "\n",
    "check_and_make_directories(\n",
    "    [DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f7fab3-aa37-434b-873f-33f1b6ffdbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tushare successfully connected\n"
     ]
    }
   ],
   "source": [
    "### Download data, cleaning and feature engineering\n",
    "\n",
    "ticker_list = [\n",
    "    \"600000.SH\",\n",
    "    \"600009.SH\",\n",
    "    \"600016.SH\",\n",
    "    \"600028.SH\",\n",
    "    \"600030.SH\",\n",
    "    \"600031.SH\",\n",
    "    \"600036.SH\",\n",
    "    \"600050.SH\",\n",
    "    \"600104.SH\",\n",
    "    \"600196.SH\",\n",
    "    \"600276.SH\",\n",
    "    \"600309.SH\",\n",
    "    \"600519.SH\",\n",
    "    \"600547.SH\",\n",
    "    \"600570.SH\",\n",
    "]\n",
    "\n",
    "TRAIN_START_DATE = \"2015-01-01\"\n",
    "TRAIN_END_DATE = \"2019-08-01\"\n",
    "TRADE_START_DATE = \"2019-08-01\"\n",
    "TRADE_END_DATE = \"2020-01-03\"\n",
    "\n",
    "\n",
    "TIME_INTERVAL = \"1d\"\n",
    "kwargs = {}\n",
    "kwargs[\"token\"] = \"53b6254438e6d307b6799dbd575883528bc1da912f3d6a31159ecc9e\"\n",
    "p = DataProcessor(\n",
    "    data_source=\"tushare\",\n",
    "    start_date=TRAIN_START_DATE,\n",
    "    end_date=TRADE_END_DATE,\n",
    "    time_interval=TIME_INTERVAL,\n",
    "    **kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab99c48-9658-436d-807f-db01258af005",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:34<00:00,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete! Dataset saved to ./data/dataset.csv. \n",
      "Shape of DataFrame: (17960, 8)\n",
      "Shape of DataFrame:  (18315, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# download and clean\n",
    "p.download_data(ticker_list=ticker_list)\n",
    "p.clean_data()\n",
    "p.fillna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7021690f-c24c-4a00-a72b-a02d6d8bded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tech_indicator_list:  ['macd', 'boll_ub', 'boll_lb', 'rsi_30', 'cci_30', 'dx_30', 'close_30_sma', 'close_60_sma']\n",
      "indicator:  macd\n",
      "indicator:  boll_ub\n",
      "indicator:  boll_lb\n",
      "indicator:  rsi_30\n",
      "indicator:  cci_30\n",
      "indicator:  dx_30\n",
      "indicator:  close_30_sma\n",
      "indicator:  close_60_sma\n",
      "Succesfully add technical indicators\n",
      "Shape of DataFrame:  (18270, 17)\n",
      "p.dataframe: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.815000</td>\n",
       "      <td>15.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>20.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.477500</td>\n",
       "      <td>10.477500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.042500</td>\n",
       "      <td>7.042500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.192500</td>\n",
       "      <td>35.192500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18265</th>\n",
       "      <td>600276.SH</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>18310</td>\n",
       "      <td>88.02</td>\n",
       "      <td>88.20</td>\n",
       "      <td>85.70</td>\n",
       "      <td>85.95</td>\n",
       "      <td>85.95</td>\n",
       "      <td>218177.79</td>\n",
       "      <td>-0.301525</td>\n",
       "      <td>87.731004</td>\n",
       "      <td>82.917996</td>\n",
       "      <td>50.964123</td>\n",
       "      <td>32.816522</td>\n",
       "      <td>9.873974</td>\n",
       "      <td>85.918667</td>\n",
       "      <td>87.503333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18266</th>\n",
       "      <td>600309.SH</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>18311</td>\n",
       "      <td>55.90</td>\n",
       "      <td>57.76</td>\n",
       "      <td>55.90</td>\n",
       "      <td>56.94</td>\n",
       "      <td>56.94</td>\n",
       "      <td>177848.57</td>\n",
       "      <td>1.921017</td>\n",
       "      <td>56.960111</td>\n",
       "      <td>49.500889</td>\n",
       "      <td>69.086313</td>\n",
       "      <td>159.628783</td>\n",
       "      <td>51.722600</td>\n",
       "      <td>51.771333</td>\n",
       "      <td>48.518333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18267</th>\n",
       "      <td>600519.SH</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>18312</td>\n",
       "      <td>1117.00</td>\n",
       "      <td>1117.00</td>\n",
       "      <td>1076.90</td>\n",
       "      <td>1078.56</td>\n",
       "      <td>1078.56</td>\n",
       "      <td>130318.78</td>\n",
       "      <td>-9.821047</td>\n",
       "      <td>1199.012393</td>\n",
       "      <td>1105.801607</td>\n",
       "      <td>41.484737</td>\n",
       "      <td>-219.877404</td>\n",
       "      <td>36.358177</td>\n",
       "      <td>1153.569333</td>\n",
       "      <td>1174.064000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18268</th>\n",
       "      <td>600547.SH</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>18313</td>\n",
       "      <td>33.21</td>\n",
       "      <td>35.25</td>\n",
       "      <td>33.10</td>\n",
       "      <td>34.78</td>\n",
       "      <td>34.78</td>\n",
       "      <td>987248.95</td>\n",
       "      <td>0.543193</td>\n",
       "      <td>33.565047</td>\n",
       "      <td>30.068953</td>\n",
       "      <td>58.038366</td>\n",
       "      <td>290.350386</td>\n",
       "      <td>54.036298</td>\n",
       "      <td>31.433667</td>\n",
       "      <td>31.491667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18269</th>\n",
       "      <td>600570.SH</td>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>18314</td>\n",
       "      <td>79.15</td>\n",
       "      <td>80.30</td>\n",
       "      <td>78.05</td>\n",
       "      <td>79.03</td>\n",
       "      <td>79.03</td>\n",
       "      <td>163653.21</td>\n",
       "      <td>0.651615</td>\n",
       "      <td>81.306518</td>\n",
       "      <td>73.780482</td>\n",
       "      <td>54.276012</td>\n",
       "      <td>92.459733</td>\n",
       "      <td>18.108638</td>\n",
       "      <td>76.242000</td>\n",
       "      <td>76.193667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18270 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             tic        time  index     open     high      low    close  \\\n",
       "0      600000.SH  2015-01-08     45    15.87    15.88    15.20    15.25   \n",
       "1      600009.SH  2015-01-08     46    20.18    20.18    19.73    20.00   \n",
       "2      600016.SH  2015-01-08     47    10.61    10.66    10.09    10.20   \n",
       "3      600028.SH  2015-01-08     48     7.09     7.41     6.83     6.85   \n",
       "4      600030.SH  2015-01-08     49    36.40    36.70    34.68    35.25   \n",
       "...          ...         ...    ...      ...      ...      ...      ...   \n",
       "18265  600276.SH  2020-01-03  18310    88.02    88.20    85.70    85.95   \n",
       "18266  600309.SH  2020-01-03  18311    55.90    57.76    55.90    56.94   \n",
       "18267  600519.SH  2020-01-03  18312  1117.00  1117.00  1076.90  1078.56   \n",
       "18268  600547.SH  2020-01-03  18313    33.21    35.25    33.10    34.78   \n",
       "18269  600570.SH  2020-01-03  18314    79.15    80.30    78.05    79.03   \n",
       "\n",
       "       adjusted_close      volume      macd      boll_ub      boll_lb  \\\n",
       "0               15.25  3306271.72 -0.032571    16.617911    15.012089   \n",
       "1               20.00   198117.45 -0.016008    20.663897    19.736103   \n",
       "2               10.20  4851684.17 -0.018247    10.957604     9.997396   \n",
       "3                6.85  8190902.35 -0.008227     7.342000     6.743000   \n",
       "4               35.25  6376268.69  0.032910    36.576444    33.808556   \n",
       "...               ...         ...       ...          ...          ...   \n",
       "18265           85.95   218177.79 -0.301525    87.731004    82.917996   \n",
       "18266           56.94   177848.57  1.921017    56.960111    49.500889   \n",
       "18267         1078.56   130318.78 -9.821047  1199.012393  1105.801607   \n",
       "18268           34.78   987248.95  0.543193    33.565047    30.068953   \n",
       "18269           79.03   163653.21  0.651615    81.306518    73.780482   \n",
       "\n",
       "          rsi_30      cci_30       dx_30  close_30_sma  close_60_sma  \n",
       "0       6.058641 -125.593009   23.014040     15.815000     15.815000  \n",
       "1      12.828915  -90.842491  100.000000     20.200000     20.200000  \n",
       "2      11.862558  -99.887006  100.000000     10.477500     10.477500  \n",
       "3      27.409248   36.578171   64.934862      7.042500      7.042500  \n",
       "4      61.517448   47.947020  100.000000     35.192500     35.192500  \n",
       "...          ...         ...         ...           ...           ...  \n",
       "18265  50.964123   32.816522    9.873974     85.918667     87.503333  \n",
       "18266  69.086313  159.628783   51.722600     51.771333     48.518333  \n",
       "18267  41.484737 -219.877404   36.358177   1153.569333   1174.064000  \n",
       "18268  58.038366  290.350386   54.036298     31.433667     31.491667  \n",
       "18269  54.276012   92.459733   18.108638     76.242000     76.193667  \n",
       "\n",
       "[18270 rows x 17 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add_technical_indicator\n",
    "p.add_technical_indicator(config.INDICATORS)\n",
    "p.fillna()\n",
    "print(f\"p.dataframe: \")\n",
    "p.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df6c0ebb-ce7e-4184-be3e-a3ee85a7f1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split traning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f8dc9a0-7575-425e-b297-9271eb42a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(train.tic.unique()): 15\n"
     ]
    }
   ],
   "source": [
    "train = p.data_split(p.dataframe, TRAIN_START_DATE, TRAIN_END_DATE)\n",
    "print(f\"len(train.tic.unique()): {len(train.tic.unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1edfb630-18c3-4297-940d-5ba4ab0b76e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['600000.SH', '600009.SH', '600016.SH', '600028.SH', '600030.SH',\n",
       "       '600031.SH', '600036.SH', '600050.SH', '600104.SH', '600196.SH',\n",
       "       '600276.SH', '600309.SH', '600519.SH', '600547.SH', '600570.SH'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.tic.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674c2cdd-a765-4b37-af3e-286851deba55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>time</th>\n",
       "      <th>index</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>macd</th>\n",
       "      <th>boll_ub</th>\n",
       "      <th>boll_lb</th>\n",
       "      <th>rsi_30</th>\n",
       "      <th>cci_30</th>\n",
       "      <th>dx_30</th>\n",
       "      <th>close_30_sma</th>\n",
       "      <th>close_60_sma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600000.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>15.87</td>\n",
       "      <td>15.88</td>\n",
       "      <td>15.20</td>\n",
       "      <td>15.25</td>\n",
       "      <td>15.25</td>\n",
       "      <td>3306271.72</td>\n",
       "      <td>-0.032571</td>\n",
       "      <td>16.617911</td>\n",
       "      <td>15.012089</td>\n",
       "      <td>6.058641</td>\n",
       "      <td>-125.593009</td>\n",
       "      <td>23.014040</td>\n",
       "      <td>15.8150</td>\n",
       "      <td>15.8150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600009.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>46</td>\n",
       "      <td>20.18</td>\n",
       "      <td>20.18</td>\n",
       "      <td>19.73</td>\n",
       "      <td>20.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>198117.45</td>\n",
       "      <td>-0.016008</td>\n",
       "      <td>20.663897</td>\n",
       "      <td>19.736103</td>\n",
       "      <td>12.828915</td>\n",
       "      <td>-90.842491</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20.2000</td>\n",
       "      <td>20.2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600016.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>47</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.66</td>\n",
       "      <td>10.09</td>\n",
       "      <td>10.20</td>\n",
       "      <td>10.20</td>\n",
       "      <td>4851684.17</td>\n",
       "      <td>-0.018247</td>\n",
       "      <td>10.957604</td>\n",
       "      <td>9.997396</td>\n",
       "      <td>11.862558</td>\n",
       "      <td>-99.887006</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>10.4775</td>\n",
       "      <td>10.4775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600028.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>48</td>\n",
       "      <td>7.09</td>\n",
       "      <td>7.41</td>\n",
       "      <td>6.83</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>8190902.35</td>\n",
       "      <td>-0.008227</td>\n",
       "      <td>7.342000</td>\n",
       "      <td>6.743000</td>\n",
       "      <td>27.409248</td>\n",
       "      <td>36.578171</td>\n",
       "      <td>64.934862</td>\n",
       "      <td>7.0425</td>\n",
       "      <td>7.0425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>600030.SH</td>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>49</td>\n",
       "      <td>36.40</td>\n",
       "      <td>36.70</td>\n",
       "      <td>34.68</td>\n",
       "      <td>35.25</td>\n",
       "      <td>35.25</td>\n",
       "      <td>6376268.69</td>\n",
       "      <td>0.032910</td>\n",
       "      <td>36.576444</td>\n",
       "      <td>33.808556</td>\n",
       "      <td>61.517448</td>\n",
       "      <td>47.947020</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>35.1925</td>\n",
       "      <td>35.1925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         tic        time  index   open   high    low  close  adjusted_close  \\\n",
       "0  600000.SH  2015-01-08     45  15.87  15.88  15.20  15.25           15.25   \n",
       "0  600009.SH  2015-01-08     46  20.18  20.18  19.73  20.00           20.00   \n",
       "0  600016.SH  2015-01-08     47  10.61  10.66  10.09  10.20           10.20   \n",
       "0  600028.SH  2015-01-08     48   7.09   7.41   6.83   6.85            6.85   \n",
       "0  600030.SH  2015-01-08     49  36.40  36.70  34.68  35.25           35.25   \n",
       "\n",
       "       volume      macd    boll_ub    boll_lb     rsi_30      cci_30  \\\n",
       "0  3306271.72 -0.032571  16.617911  15.012089   6.058641 -125.593009   \n",
       "0   198117.45 -0.016008  20.663897  19.736103  12.828915  -90.842491   \n",
       "0  4851684.17 -0.018247  10.957604   9.997396  11.862558  -99.887006   \n",
       "0  8190902.35 -0.008227   7.342000   6.743000  27.409248   36.578171   \n",
       "0  6376268.69  0.032910  36.576444  33.808556  61.517448   47.947020   \n",
       "\n",
       "        dx_30  close_30_sma  close_60_sma  \n",
       "0   23.014040       15.8150       15.8150  \n",
       "0  100.000000       20.2000       20.2000  \n",
       "0  100.000000       10.4775       10.4775  \n",
       "0   64.934862        7.0425        7.0425  \n",
       "0  100.000000       35.1925       35.1925  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3a830c0-3639-4c1f-9b8e-2bc751b62fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16695, 17)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8401eb44-ebf4-4436-9bd9-cfa80d273f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Dimension: 15, State Space: 151\n"
     ]
    }
   ],
   "source": [
    "stock_dimension = len(train.tic.unique())\n",
    "state_space = stock_dimension * (len(config.INDICATORS) + 2) + 1\n",
    "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436a6299-c6ff-437f-b3df-123212db5cdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ad2a5b-a1bd-4341-8f76-a3cbb22a5265",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60cd4a3c-4693-4f21-84b2-1777cda69466",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 如果不加这个，会报错的。\n",
    "train[\"date\"] = train.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afb4e0b1-a537-4ad6-b1dc-16426ed98c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train\n",
    "\n",
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"buy_cost_pct\": 6.87e-5,\n",
    "    \"sell_cost_pct\": 1.0687e-3,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\": True,\n",
    "    \"hundred_each_trade\": False, ## 如果为True，会报错，可能是库代码写的问题。\n",
    "}\n",
    "\n",
    "e_train_gym = StockTradingEnv(df=train, **env_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350a34b-c433-4a85-ab9a-5f02233c6cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4dc3e5f-9ac9-46df-ac0a-af5785f258c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b078eb0-2ccb-400a-9da4-38bab167ebf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c671b6d1-9c8e-4135-b478-b60c02bbbabd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'stable_baselines3.common.vec_env.dummy_vec_env.DummyVecEnv'>\n",
      "print(type(env_train)): None\n",
      "{'batch_size': 256, 'buffer_size': 50000, 'learning_rate': 0.0005, 'action_noise': NormalActionNoise(mu=[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.], sigma=[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1])}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/ddpg/ddpg_1\n",
      "Episode: 2\n",
      "day: 1112, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1596003.66\n",
      "total_reward: 596003.66\n",
      "total_cost: 11603.15\n",
      "total_trades: 1363\n",
      "Sharpe: 0.483\n",
      "=================================\n",
      "Episode: 3\n",
      "day: 1112, episode: 3\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1511559.50\n",
      "total_reward: 511559.50\n",
      "total_cost: 411.90\n",
      "total_trades: 73\n",
      "Sharpe: 0.459\n",
      "=================================\n",
      "Episode: 4\n",
      "day: 1112, episode: 4\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1511809.50\n",
      "total_reward: 511809.50\n",
      "total_cost: 411.87\n",
      "total_trades: 74\n",
      "Sharpe: 0.460\n",
      "=================================\n",
      "Episode: 5\n",
      "day: 1112, episode: 5\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1514541.05\n",
      "total_reward: 514541.05\n",
      "total_cost: 411.90\n",
      "total_trades: 73\n",
      "Sharpe: 0.460\n",
      "=================================\n",
      "------------------------------------\n",
      "| time/              |             |\n",
      "|    episodes        | 4           |\n",
      "|    fps             | 305         |\n",
      "|    time_elapsed    | 14          |\n",
      "|    total_timesteps | 4452        |\n",
      "| train/             |             |\n",
      "|    actor_loss      | 102         |\n",
      "|    critic_loss     | 13.7        |\n",
      "|    learning_rate   | 0.0005      |\n",
      "|    n_updates       | 4351        |\n",
      "|    reward          | -0.15145409 |\n",
      "------------------------------------\n",
      "Episode: 6\n",
      "day: 1112, episode: 6\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1511932.03\n",
      "total_reward: 511932.03\n",
      "total_cost: 411.85\n",
      "total_trades: 72\n",
      "Sharpe: 0.460\n",
      "=================================\n",
      "Episode: 7\n",
      "day: 1112, episode: 7\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1509010.58\n",
      "total_reward: 509010.58\n",
      "total_cost: 411.88\n",
      "total_trades: 75\n",
      "Sharpe: 0.458\n",
      "=================================\n",
      "Episode: 8\n",
      "day: 1112, episode: 8\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1500146.93\n",
      "total_reward: 500146.93\n",
      "total_cost: 411.94\n",
      "total_trades: 74\n",
      "Sharpe: 0.454\n",
      "=================================\n",
      "Episode: 9\n",
      "day: 1112, episode: 9\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1488678.13\n",
      "total_reward: 488678.13\n",
      "total_cost: 411.99\n",
      "total_trades: 75\n",
      "Sharpe: 0.449\n",
      "=================================\n",
      "-----------------------------------\n",
      "| time/              |            |\n",
      "|    episodes        | 8          |\n",
      "|    fps             | 301        |\n",
      "|    time_elapsed    | 29         |\n",
      "|    total_timesteps | 8904       |\n",
      "| train/             |            |\n",
      "|    actor_loss      | 95.8       |\n",
      "|    critic_loss     | 5.65       |\n",
      "|    learning_rate   | 0.0005     |\n",
      "|    n_updates       | 8803       |\n",
      "|    reward          | -0.1488677 |\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "## DDPG\n",
    "\n",
    "env_train, _ = e_train_gym.get_sb_env()\n",
    "print(f\"print(type(env_train)): {print(type(env_train))}\")\n",
    "\n",
    "agent = DRLAgent(env=env_train)\n",
    "DDPG_PARAMS = {\n",
    "    \"batch_size\": 256,\n",
    "    \"buffer_size\": 50000,\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"action_noise\": \"normal\",\n",
    "}\n",
    "POLICY_KWARGS = dict(net_arch=dict(pi=[64, 64], qf=[400, 300]))\n",
    "model_ddpg = agent.get_model(\n",
    "    \"ddpg\", model_kwargs=DDPG_PARAMS, policy_kwargs=POLICY_KWARGS\n",
    ")\n",
    "\n",
    "trained_ddpg = agent.train_model(\n",
    "    model=model_ddpg, tb_log_name=\"ddpg\", total_timesteps=10000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4d4f96-71d7-4500-9aa0-6f101395e1cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce84f1cd-9815-4b66-8b2e-118bcc020b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2d1bdb4-7601-46b9-800e-e85d9eb7c59b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_steps': 5, 'ent_coef': 0.01, 'learning_rate': 0.0007}\n",
      "Using cpu device\n",
      "Logging to tensorboard_log/a2c/a2c_1\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 915          |\n",
      "|    iterations         | 100          |\n",
      "|    time_elapsed       | 0            |\n",
      "|    total_timesteps    | 500          |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.5        |\n",
      "|    explained_variance | -9.69        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 99           |\n",
      "|    policy_loss        | -9.16        |\n",
      "|    reward             | -0.015446212 |\n",
      "|    std                | 1.01         |\n",
      "|    value_loss         | 0.238        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 912          |\n",
      "|    iterations         | 200          |\n",
      "|    time_elapsed       | 1            |\n",
      "|    total_timesteps    | 1000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -21.6        |\n",
      "|    explained_variance | -6.2         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 199          |\n",
      "|    policy_loss        | -7.3         |\n",
      "|    reward             | -0.044587296 |\n",
      "|    std                | 1.02         |\n",
      "|    value_loss         | 0.234        |\n",
      "----------------------------------------\n",
      "Episode: 11\n",
      "day: 1112, episode: 11\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 2189223.35\n",
      "total_reward: 1189223.35\n",
      "total_cost: 189861.58\n",
      "total_trades: 11411\n",
      "Sharpe: 0.808\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 899         |\n",
      "|    iterations         | 300         |\n",
      "|    time_elapsed       | 1           |\n",
      "|    total_timesteps    | 1500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.8       |\n",
      "|    explained_variance | -230        |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 299         |\n",
      "|    policy_loss        | -1.42       |\n",
      "|    reward             | -0.11188739 |\n",
      "|    std                | 1.03        |\n",
      "|    value_loss         | 0.023       |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 909         |\n",
      "|    iterations         | 400         |\n",
      "|    time_elapsed       | 2           |\n",
      "|    total_timesteps    | 2000        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -21.9       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 399         |\n",
      "|    policy_loss        | 11.3        |\n",
      "|    reward             | -0.01614339 |\n",
      "|    std                | 1.04        |\n",
      "|    value_loss         | 0.248       |\n",
      "---------------------------------------\n",
      "Episode: 12\n",
      "day: 1112, episode: 12\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1791180.45\n",
      "total_reward: 791180.45\n",
      "total_cost: 143144.69\n",
      "total_trades: 11971\n",
      "Sharpe: 0.685\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 917          |\n",
      "|    iterations         | 500          |\n",
      "|    time_elapsed       | 2            |\n",
      "|    total_timesteps    | 2500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22          |\n",
      "|    explained_variance | -4.11e+03    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 499          |\n",
      "|    policy_loss        | 2.1          |\n",
      "|    reward             | -0.008520361 |\n",
      "|    std                | 1.05         |\n",
      "|    value_loss         | 0.191        |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 924          |\n",
      "|    iterations         | 600          |\n",
      "|    time_elapsed       | 3            |\n",
      "|    total_timesteps    | 3000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.1        |\n",
      "|    explained_variance | -43.7        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 599          |\n",
      "|    policy_loss        | 2.33         |\n",
      "|    reward             | -0.007474793 |\n",
      "|    std                | 1.06         |\n",
      "|    value_loss         | 0.0473       |\n",
      "----------------------------------------\n",
      "Episode: 13\n",
      "day: 1112, episode: 13\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1400182.08\n",
      "total_reward: 400182.08\n",
      "total_cost: 85766.11\n",
      "total_trades: 10706\n",
      "Sharpe: 0.415\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 923           |\n",
      "|    iterations         | 700           |\n",
      "|    time_elapsed       | 3             |\n",
      "|    total_timesteps    | 3500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -22.4         |\n",
      "|    explained_variance | 1.19e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 699           |\n",
      "|    policy_loss        | 0.125         |\n",
      "|    reward             | -0.0036852285 |\n",
      "|    std                | 1.07          |\n",
      "|    value_loss         | 4.25e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 927          |\n",
      "|    iterations         | 800          |\n",
      "|    time_elapsed       | 4            |\n",
      "|    total_timesteps    | 4000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -22.9        |\n",
      "|    explained_variance | -570         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 799          |\n",
      "|    policy_loss        | -0.216       |\n",
      "|    reward             | -0.009880056 |\n",
      "|    std                | 1.11         |\n",
      "|    value_loss         | 0.00188      |\n",
      "----------------------------------------\n",
      "Episode: 14\n",
      "day: 1112, episode: 14\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1441361.59\n",
      "total_reward: 441361.59\n",
      "total_cost: 84710.02\n",
      "total_trades: 10681\n",
      "Sharpe: 0.521\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 931           |\n",
      "|    iterations         | 900           |\n",
      "|    time_elapsed       | 4             |\n",
      "|    total_timesteps    | 4500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -23.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 899           |\n",
      "|    policy_loss        | -0.342        |\n",
      "|    reward             | -0.0035377727 |\n",
      "|    std                | 1.14          |\n",
      "|    value_loss         | 0.000218      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 934          |\n",
      "|    iterations         | 1000         |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 5000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -23.7        |\n",
      "|    explained_variance | 1.79e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 999          |\n",
      "|    policy_loss        | 0.0438       |\n",
      "|    reward             | -0.005284144 |\n",
      "|    std                | 1.18         |\n",
      "|    value_loss         | 6.73e-06     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 936          |\n",
      "|    iterations         | 1100         |\n",
      "|    time_elapsed       | 5            |\n",
      "|    total_timesteps    | 5500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.1        |\n",
      "|    explained_variance | -396         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1099         |\n",
      "|    policy_loss        | 11           |\n",
      "|    reward             | -0.002756181 |\n",
      "|    std                | 1.21         |\n",
      "|    value_loss         | 0.536        |\n",
      "----------------------------------------\n",
      "Episode: 15\n",
      "day: 1112, episode: 15\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1203041.73\n",
      "total_reward: 203041.73\n",
      "total_cost: 71710.73\n",
      "total_trades: 9846\n",
      "Sharpe: 0.337\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 937          |\n",
      "|    iterations         | 1200         |\n",
      "|    time_elapsed       | 6            |\n",
      "|    total_timesteps    | 6000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -24.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1199         |\n",
      "|    policy_loss        | 0.097        |\n",
      "|    reward             | -0.005582782 |\n",
      "|    std                | 1.25         |\n",
      "|    value_loss         | 1.7e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 936           |\n",
      "|    iterations         | 1300          |\n",
      "|    time_elapsed       | 6             |\n",
      "|    total_timesteps    | 6500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.2         |\n",
      "|    explained_variance | -9.06         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1299          |\n",
      "|    policy_loss        | -3.18         |\n",
      "|    reward             | -0.0024529058 |\n",
      "|    std                | 1.3           |\n",
      "|    value_loss         | 0.0161        |\n",
      "-----------------------------------------\n",
      "Episode: 16\n",
      "day: 1112, episode: 16\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 793873.33\n",
      "total_reward: -206126.67\n",
      "total_cost: 55285.38\n",
      "total_trades: 7860\n",
      "Sharpe: -0.083\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 936           |\n",
      "|    iterations         | 1400          |\n",
      "|    time_elapsed       | 7             |\n",
      "|    total_timesteps    | 7000          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -25.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1399          |\n",
      "|    policy_loss        | 0.0995        |\n",
      "|    reward             | -0.0029675243 |\n",
      "|    std                | 1.34          |\n",
      "|    value_loss         | 3.09e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 938          |\n",
      "|    iterations         | 1500         |\n",
      "|    time_elapsed       | 7            |\n",
      "|    total_timesteps    | 7500         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.3        |\n",
      "|    explained_variance | -15.1        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1499         |\n",
      "|    policy_loss        | -0.826       |\n",
      "|    reward             | -0.005970611 |\n",
      "|    std                | 1.4          |\n",
      "|    value_loss         | 0.00389      |\n",
      "----------------------------------------\n",
      "Episode: 17\n",
      "day: 1112, episode: 17\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1496247.99\n",
      "total_reward: 496247.99\n",
      "total_cost: 62828.17\n",
      "total_trades: 8110\n",
      "Sharpe: 0.498\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 937          |\n",
      "|    iterations         | 1600         |\n",
      "|    time_elapsed       | 8            |\n",
      "|    total_timesteps    | 8000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -26.6        |\n",
      "|    explained_variance | -168         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1599         |\n",
      "|    policy_loss        | -1.16        |\n",
      "|    reward             | -0.005184354 |\n",
      "|    std                | 1.43         |\n",
      "|    value_loss         | 0.00268      |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 937         |\n",
      "|    iterations         | 1700        |\n",
      "|    time_elapsed       | 9           |\n",
      "|    total_timesteps    | 8500        |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -27         |\n",
      "|    explained_variance | -4.69e+03   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 1699        |\n",
      "|    policy_loss        | 3.03        |\n",
      "|    reward             | -0.01245125 |\n",
      "|    std                | 1.46        |\n",
      "|    value_loss         | 0.151       |\n",
      "---------------------------------------\n",
      "Episode: 18\n",
      "day: 1112, episode: 18\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 860549.98\n",
      "total_reward: -139450.02\n",
      "total_cost: 55541.69\n",
      "total_trades: 7533\n",
      "Sharpe: -0.019\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 937          |\n",
      "|    iterations         | 1800         |\n",
      "|    time_elapsed       | 9            |\n",
      "|    total_timesteps    | 9000         |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -27.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 1799         |\n",
      "|    policy_loss        | -0.122       |\n",
      "|    reward             | -0.004623345 |\n",
      "|    std                | 1.5          |\n",
      "|    value_loss         | 3.89e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 938           |\n",
      "|    iterations         | 1900          |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 9500          |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -27.9         |\n",
      "|    explained_variance | -589          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1899          |\n",
      "|    policy_loss        | -1.79         |\n",
      "|    reward             | -0.0012275719 |\n",
      "|    std                | 1.55          |\n",
      "|    value_loss         | 0.0107        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 938           |\n",
      "|    iterations         | 2000          |\n",
      "|    time_elapsed       | 10            |\n",
      "|    total_timesteps    | 10000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.3         |\n",
      "|    explained_variance | -19.9         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 1999          |\n",
      "|    policy_loss        | 4.36          |\n",
      "|    reward             | -0.0020270245 |\n",
      "|    std                | 1.6           |\n",
      "|    value_loss         | 0.0237        |\n",
      "-----------------------------------------\n",
      "Episode: 19\n",
      "day: 1112, episode: 19\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 905802.17\n",
      "total_reward: -94197.83\n",
      "total_cost: 43861.84\n",
      "total_trades: 6708\n",
      "Sharpe: -0.025\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 938           |\n",
      "|    iterations         | 2100          |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 10500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -28.7         |\n",
      "|    explained_variance | -0.286        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2099          |\n",
      "|    policy_loss        | -2.92         |\n",
      "|    reward             | -0.0015888698 |\n",
      "|    std                | 1.65          |\n",
      "|    value_loss         | 0.0135        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 939           |\n",
      "|    iterations         | 2200          |\n",
      "|    time_elapsed       | 11            |\n",
      "|    total_timesteps    | 11000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.1         |\n",
      "|    explained_variance | -29.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2199          |\n",
      "|    policy_loss        | 0.184         |\n",
      "|    reward             | -0.0079661915 |\n",
      "|    std                | 1.69          |\n",
      "|    value_loss         | 0.000188      |\n",
      "-----------------------------------------\n",
      "Episode: 20\n",
      "day: 1112, episode: 20\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 917004.80\n",
      "total_reward: -82995.20\n",
      "total_cost: 42037.59\n",
      "total_trades: 6136\n",
      "Sharpe: 0.072\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 938           |\n",
      "|    iterations         | 2300          |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 11500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -29.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2299          |\n",
      "|    policy_loss        | -0.0217       |\n",
      "|    reward             | -0.0055536213 |\n",
      "|    std                | 1.75          |\n",
      "|    value_loss         | 3.24e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 939           |\n",
      "|    iterations         | 2400          |\n",
      "|    time_elapsed       | 12            |\n",
      "|    total_timesteps    | 12000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -30.3         |\n",
      "|    explained_variance | -3.06         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2399          |\n",
      "|    policy_loss        | 0.313         |\n",
      "|    reward             | -0.0064101247 |\n",
      "|    std                | 1.82          |\n",
      "|    value_loss         | 0.000154      |\n",
      "-----------------------------------------\n",
      "Episode: 21\n",
      "day: 1112, episode: 21\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1007615.13\n",
      "total_reward: 7615.13\n",
      "total_cost: 29749.22\n",
      "total_trades: 5031\n",
      "Sharpe: 0.121\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 936          |\n",
      "|    iterations         | 2500         |\n",
      "|    time_elapsed       | 13           |\n",
      "|    total_timesteps    | 12500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -30.9        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 2499         |\n",
      "|    policy_loss        | -0.0586      |\n",
      "|    reward             | -0.004702913 |\n",
      "|    std                | 1.91         |\n",
      "|    value_loss         | 6.58e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 936           |\n",
      "|    iterations         | 2600          |\n",
      "|    time_elapsed       | 13            |\n",
      "|    total_timesteps    | 13000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -31.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2599          |\n",
      "|    policy_loss        | 0.357         |\n",
      "|    reward             | -0.0077993465 |\n",
      "|    std                | 2.01          |\n",
      "|    value_loss         | 0.000154      |\n",
      "-----------------------------------------\n",
      "Episode: 22\n",
      "day: 1112, episode: 22\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 981743.13\n",
      "total_reward: -18256.87\n",
      "total_cost: 29127.92\n",
      "total_trades: 4830\n",
      "Sharpe: 0.028\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 936           |\n",
      "|    iterations         | 2700          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 13500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -32.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2699          |\n",
      "|    policy_loss        | 0.141         |\n",
      "|    reward             | -0.0018955498 |\n",
      "|    std                | 2.14          |\n",
      "|    value_loss         | 1.92e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 936           |\n",
      "|    iterations         | 2800          |\n",
      "|    time_elapsed       | 14            |\n",
      "|    total_timesteps    | 14000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -33.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2799          |\n",
      "|    policy_loss        | 0.082         |\n",
      "|    reward             | -0.0015042722 |\n",
      "|    std                | 2.27          |\n",
      "|    value_loss         | 7.6e-06       |\n",
      "-----------------------------------------\n",
      "Episode: 23\n",
      "day: 1112, episode: 23\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 950353.74\n",
      "total_reward: -49646.26\n",
      "total_cost: 26299.66\n",
      "total_trades: 4424\n",
      "Sharpe: -0.050\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 935           |\n",
      "|    iterations         | 2900          |\n",
      "|    time_elapsed       | 15            |\n",
      "|    total_timesteps    | 14500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -34.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2899          |\n",
      "|    policy_loss        | -0.264        |\n",
      "|    reward             | -0.0015603644 |\n",
      "|    std                | 2.41          |\n",
      "|    value_loss         | 6.34e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 936           |\n",
      "|    iterations         | 3000          |\n",
      "|    time_elapsed       | 16            |\n",
      "|    total_timesteps    | 15000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -35.4         |\n",
      "|    explained_variance | -49.9         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 2999          |\n",
      "|    policy_loss        | 0.578         |\n",
      "|    reward             | -0.0007572528 |\n",
      "|    std                | 2.56          |\n",
      "|    value_loss         | 0.000439      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 936          |\n",
      "|    iterations         | 3100         |\n",
      "|    time_elapsed       | 16           |\n",
      "|    total_timesteps    | 15500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -35.8        |\n",
      "|    explained_variance | -194         |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3099         |\n",
      "|    policy_loss        | 1.08         |\n",
      "|    reward             | -0.003393853 |\n",
      "|    std                | 2.64         |\n",
      "|    value_loss         | 0.0017       |\n",
      "----------------------------------------\n",
      "Episode: 24\n",
      "day: 1112, episode: 24\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 948615.12\n",
      "total_reward: -51384.88\n",
      "total_cost: 21228.55\n",
      "total_trades: 4132\n",
      "Sharpe: 0.092\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 937           |\n",
      "|    iterations         | 3200          |\n",
      "|    time_elapsed       | 17            |\n",
      "|    total_timesteps    | 16000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -36.4         |\n",
      "|    explained_variance | -72.3         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3199          |\n",
      "|    policy_loss        | -0.226        |\n",
      "|    reward             | -0.0012845108 |\n",
      "|    std                | 2.75          |\n",
      "|    value_loss         | 5.33e-05      |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                 |                |\n",
      "|    fps                | 937            |\n",
      "|    iterations         | 3300           |\n",
      "|    time_elapsed       | 17             |\n",
      "|    total_timesteps    | 16500          |\n",
      "| train/                |                |\n",
      "|    entropy_loss       | -37.2          |\n",
      "|    explained_variance | -0.844         |\n",
      "|    learning_rate      | 0.0007         |\n",
      "|    n_updates          | 3299           |\n",
      "|    policy_loss        | 0.37           |\n",
      "|    reward             | -0.00048118705 |\n",
      "|    std                | 2.89           |\n",
      "|    value_loss         | 0.000103       |\n",
      "------------------------------------------\n",
      "Episode: 25\n",
      "day: 1112, episode: 25\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1031385.44\n",
      "total_reward: 31385.44\n",
      "total_cost: 22447.26\n",
      "total_trades: 3835\n",
      "Sharpe: 0.141\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 937          |\n",
      "|    iterations         | 3400         |\n",
      "|    time_elapsed       | 18           |\n",
      "|    total_timesteps    | 17000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -37.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3399         |\n",
      "|    policy_loss        | -0.0569      |\n",
      "|    reward             | -6.20585e-05 |\n",
      "|    std                | 3.02         |\n",
      "|    value_loss         | 4.02e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 937           |\n",
      "|    iterations         | 3500          |\n",
      "|    time_elapsed       | 18            |\n",
      "|    total_timesteps    | 17500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -38.6         |\n",
      "|    explained_variance | 0.299         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3499          |\n",
      "|    policy_loss        | -0.0735       |\n",
      "|    reward             | -0.0015303784 |\n",
      "|    std                | 3.18          |\n",
      "|    value_loss         | 5.5e-06       |\n",
      "-----------------------------------------\n",
      "Episode: 26\n",
      "day: 1112, episode: 26\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1076229.39\n",
      "total_reward: 76229.39\n",
      "total_cost: 21878.72\n",
      "total_trades: 3712\n",
      "Sharpe: 0.197\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 934          |\n",
      "|    iterations         | 3600         |\n",
      "|    time_elapsed       | 19           |\n",
      "|    total_timesteps    | 18000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -39.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 3599         |\n",
      "|    policy_loss        | -0.739       |\n",
      "|    reward             | -0.002812454 |\n",
      "|    std                | 3.34         |\n",
      "|    value_loss         | 0.000325     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 934           |\n",
      "|    iterations         | 3700          |\n",
      "|    time_elapsed       | 19            |\n",
      "|    total_timesteps    | 18500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -40.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3699          |\n",
      "|    policy_loss        | -0.053        |\n",
      "|    reward             | -0.0011710498 |\n",
      "|    std                | 3.52          |\n",
      "|    value_loss         | 1.5e-05       |\n",
      "-----------------------------------------\n",
      "Episode: 27\n",
      "day: 1112, episode: 27\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 927235.70\n",
      "total_reward: -72764.30\n",
      "total_cost: 23325.47\n",
      "total_trades: 3777\n",
      "Sharpe: -0.535\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 933           |\n",
      "|    iterations         | 3800          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 19000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41           |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3799          |\n",
      "|    policy_loss        | -0.109        |\n",
      "|    reward             | -0.0009137385 |\n",
      "|    std                | 3.73          |\n",
      "|    value_loss         | 7.97e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 933           |\n",
      "|    iterations         | 3900          |\n",
      "|    time_elapsed       | 20            |\n",
      "|    total_timesteps    | 19500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -41.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3899          |\n",
      "|    policy_loss        | -0.00489      |\n",
      "|    reward             | -0.0016875217 |\n",
      "|    std                | 3.97          |\n",
      "|    value_loss         | 2.94e-06      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 934           |\n",
      "|    iterations         | 4000          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 20000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -42.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 3999          |\n",
      "|    policy_loss        | -0.18         |\n",
      "|    reward             | -0.0002104968 |\n",
      "|    std                | 4.21          |\n",
      "|    value_loss         | 1.98e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 28\n",
      "day: 1112, episode: 28\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 966189.06\n",
      "total_reward: -33810.94\n",
      "total_cost: 28065.02\n",
      "total_trades: 4076\n",
      "Sharpe: -0.052\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 933           |\n",
      "|    iterations         | 4100          |\n",
      "|    time_elapsed       | 21            |\n",
      "|    total_timesteps    | 20500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -43.7         |\n",
      "|    explained_variance | 1.79e-07      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4099          |\n",
      "|    policy_loss        | -0.0282       |\n",
      "|    reward             | -0.0001541628 |\n",
      "|    std                | 4.45          |\n",
      "|    value_loss         | 1.19e-05      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 934           |\n",
      "|    iterations         | 4200          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 21000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -44.5         |\n",
      "|    explained_variance | -226          |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4199          |\n",
      "|    policy_loss        | -0.519        |\n",
      "|    reward             | -0.0061162473 |\n",
      "|    std                | 4.72          |\n",
      "|    value_loss         | 0.000468      |\n",
      "-----------------------------------------\n",
      "Episode: 29\n",
      "day: 1112, episode: 29\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 885786.11\n",
      "total_reward: -114213.89\n",
      "total_cost: 28187.91\n",
      "total_trades: 4118\n",
      "Sharpe: -0.099\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 934           |\n",
      "|    iterations         | 4300          |\n",
      "|    time_elapsed       | 22            |\n",
      "|    total_timesteps    | 21500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -45.3         |\n",
      "|    explained_variance | -15           |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4299          |\n",
      "|    policy_loss        | 0.126         |\n",
      "|    reward             | -0.0010790379 |\n",
      "|    std                | 4.98          |\n",
      "|    value_loss         | 2.2e-05       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 935           |\n",
      "|    iterations         | 4400          |\n",
      "|    time_elapsed       | 23            |\n",
      "|    total_timesteps    | 22000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -46           |\n",
      "|    explained_variance | -4.24         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4399          |\n",
      "|    policy_loss        | -0.248        |\n",
      "|    reward             | -0.0006739072 |\n",
      "|    std                | 5.22          |\n",
      "|    value_loss         | 5e-05         |\n",
      "-----------------------------------------\n",
      "Episode: 30\n",
      "day: 1112, episode: 30\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1077495.18\n",
      "total_reward: 77495.18\n",
      "total_cost: 31484.38\n",
      "total_trades: 4261\n",
      "Sharpe: 0.194\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 935          |\n",
      "|    iterations         | 4500         |\n",
      "|    time_elapsed       | 24           |\n",
      "|    total_timesteps    | 22500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -46.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4499         |\n",
      "|    policy_loss        | 0.143        |\n",
      "|    reward             | -0.000595928 |\n",
      "|    std                | 5.43         |\n",
      "|    value_loss         | 1.13e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 935           |\n",
      "|    iterations         | 4600          |\n",
      "|    time_elapsed       | 24            |\n",
      "|    total_timesteps    | 23000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -47.4         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4599          |\n",
      "|    policy_loss        | 0.205         |\n",
      "|    reward             | -0.0014316918 |\n",
      "|    std                | 5.71          |\n",
      "|    value_loss         | 1.91e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 31\n",
      "day: 1112, episode: 31\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 938225.40\n",
      "total_reward: -61774.60\n",
      "total_cost: 35252.14\n",
      "total_trades: 4353\n",
      "Sharpe: -0.337\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 935           |\n",
      "|    iterations         | 4700          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 23500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -48.2         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4699          |\n",
      "|    policy_loss        | 0.455         |\n",
      "|    reward             | -0.0027516808 |\n",
      "|    std                | 6.04          |\n",
      "|    value_loss         | 0.000115      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 936           |\n",
      "|    iterations         | 4800          |\n",
      "|    time_elapsed       | 25            |\n",
      "|    total_timesteps    | 24000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.1         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4799          |\n",
      "|    policy_loss        | -0.519        |\n",
      "|    reward             | -0.0016049257 |\n",
      "|    std                | 6.4           |\n",
      "|    value_loss         | 0.000144      |\n",
      "-----------------------------------------\n",
      "Episode: 32\n",
      "day: 1112, episode: 32\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 930863.80\n",
      "total_reward: -69136.20\n",
      "total_cost: 45627.70\n",
      "total_trades: 4808\n",
      "Sharpe: -0.465\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 935           |\n",
      "|    iterations         | 4900          |\n",
      "|    time_elapsed       | 26            |\n",
      "|    total_timesteps    | 24500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -49.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 4899          |\n",
      "|    policy_loss        | -0.126        |\n",
      "|    reward             | -0.0031623614 |\n",
      "|    std                | 6.76          |\n",
      "|    value_loss         | 1.28e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 935          |\n",
      "|    iterations         | 5000         |\n",
      "|    time_elapsed       | 26           |\n",
      "|    total_timesteps    | 25000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -50.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 4999         |\n",
      "|    policy_loss        | 0.324        |\n",
      "|    reward             | -0.008392315 |\n",
      "|    std                | 7.09         |\n",
      "|    value_loss         | 4.65e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 935           |\n",
      "|    iterations         | 5100          |\n",
      "|    time_elapsed       | 27            |\n",
      "|    total_timesteps    | 25500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -51.4         |\n",
      "|    explained_variance | 5.96e-08      |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5099          |\n",
      "|    policy_loss        | -0.301        |\n",
      "|    reward             | -0.0019261145 |\n",
      "|    std                | 7.48          |\n",
      "|    value_loss         | 0.000125      |\n",
      "-----------------------------------------\n",
      "Episode: 33\n",
      "day: 1112, episode: 33\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 873324.40\n",
      "total_reward: -126675.60\n",
      "total_cost: 50105.83\n",
      "total_trades: 5485\n",
      "Sharpe: -0.574\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 935          |\n",
      "|    iterations         | 5200         |\n",
      "|    time_elapsed       | 27           |\n",
      "|    total_timesteps    | 26000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -52.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5199         |\n",
      "|    policy_loss        | -0.0779      |\n",
      "|    reward             | -0.009480285 |\n",
      "|    std                | 7.89         |\n",
      "|    value_loss         | 1.77e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 935          |\n",
      "|    iterations         | 5300         |\n",
      "|    time_elapsed       | 28           |\n",
      "|    total_timesteps    | 26500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -53          |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5299         |\n",
      "|    policy_loss        | 0.24         |\n",
      "|    reward             | -0.004508671 |\n",
      "|    std                | 8.35         |\n",
      "|    value_loss         | 2.47e-05     |\n",
      "----------------------------------------\n",
      "Episode: 34\n",
      "day: 1112, episode: 34\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 910934.33\n",
      "total_reward: -89065.67\n",
      "total_cost: 58832.14\n",
      "total_trades: 5966\n",
      "Sharpe: -0.362\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 935           |\n",
      "|    iterations         | 5400          |\n",
      "|    time_elapsed       | 28            |\n",
      "|    total_timesteps    | 27000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -53.7         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5399          |\n",
      "|    policy_loss        | 0.251         |\n",
      "|    reward             | -0.0033871168 |\n",
      "|    std                | 8.75          |\n",
      "|    value_loss         | 2.41e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 933          |\n",
      "|    iterations         | 5500         |\n",
      "|    time_elapsed       | 29           |\n",
      "|    total_timesteps    | 27500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -54.5        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5499         |\n",
      "|    policy_loss        | -0.511       |\n",
      "|    reward             | -0.009034749 |\n",
      "|    std                | 9.21         |\n",
      "|    value_loss         | 0.000222     |\n",
      "----------------------------------------\n",
      "Episode: 35\n",
      "day: 1112, episode: 35\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 956274.02\n",
      "total_reward: -43725.98\n",
      "total_cost: 59385.01\n",
      "total_trades: 6172\n",
      "Sharpe: -0.211\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 929           |\n",
      "|    iterations         | 5600          |\n",
      "|    time_elapsed       | 30            |\n",
      "|    total_timesteps    | 28000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -55.3         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5599          |\n",
      "|    policy_loss        | 0.248         |\n",
      "|    reward             | -0.0024394342 |\n",
      "|    std                | 9.71          |\n",
      "|    value_loss         | 3.73e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 929          |\n",
      "|    iterations         | 5700         |\n",
      "|    time_elapsed       | 30           |\n",
      "|    total_timesteps    | 28500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.1        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5699         |\n",
      "|    policy_loss        | 0.0915       |\n",
      "|    reward             | -0.010169191 |\n",
      "|    std                | 10.3         |\n",
      "|    value_loss         | 9.2e-06      |\n",
      "----------------------------------------\n",
      "Episode: 36\n",
      "day: 1112, episode: 36\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 791212.27\n",
      "total_reward: -208787.73\n",
      "total_cost: 67585.69\n",
      "total_trades: 6598\n",
      "Sharpe: -0.816\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 929          |\n",
      "|    iterations         | 5800         |\n",
      "|    time_elapsed       | 31           |\n",
      "|    total_timesteps    | 29000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -56.9        |\n",
      "|    explained_variance | 5.96e-08     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5799         |\n",
      "|    policy_loss        | 0.602        |\n",
      "|    reward             | -0.007486586 |\n",
      "|    std                | 10.8         |\n",
      "|    value_loss         | 0.00014      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 5900          |\n",
      "|    time_elapsed       | 31            |\n",
      "|    total_timesteps    | 29500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -57.7         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 5899          |\n",
      "|    policy_loss        | 0.337         |\n",
      "|    reward             | -0.0057480833 |\n",
      "|    std                | 11.4          |\n",
      "|    value_loss         | 3.83e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 930          |\n",
      "|    iterations         | 6000         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 30000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -58.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 5999         |\n",
      "|    policy_loss        | 0.139        |\n",
      "|    reward             | -0.013989723 |\n",
      "|    std                | 12           |\n",
      "|    value_loss         | 6.62e-06     |\n",
      "----------------------------------------\n",
      "Episode: 37\n",
      "day: 1112, episode: 37\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1024408.88\n",
      "total_reward: 24408.88\n",
      "total_cost: 71438.31\n",
      "total_trades: 6795\n",
      "Sharpe: 0.145\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 930          |\n",
      "|    iterations         | 6100         |\n",
      "|    time_elapsed       | 32           |\n",
      "|    total_timesteps    | 30500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -59.2        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6099         |\n",
      "|    policy_loss        | 0.188        |\n",
      "|    reward             | -0.012720161 |\n",
      "|    std                | 12.6         |\n",
      "|    value_loss         | 2.2e-05      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 6200          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 31000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -59.9         |\n",
      "|    explained_variance | -1.19e-07     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6199          |\n",
      "|    policy_loss        | 0.428         |\n",
      "|    reward             | -0.0066602216 |\n",
      "|    std                | 13.2          |\n",
      "|    value_loss         | 5.98e-05      |\n",
      "-----------------------------------------\n",
      "Episode: 38\n",
      "day: 1112, episode: 38\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 944371.84\n",
      "total_reward: -55628.16\n",
      "total_cost: 83088.67\n",
      "total_trades: 7515\n",
      "Sharpe: -0.099\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 6300          |\n",
      "|    time_elapsed       | 33            |\n",
      "|    total_timesteps    | 31500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -60.5         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6299          |\n",
      "|    policy_loss        | 0.0271        |\n",
      "|    reward             | -0.0017240718 |\n",
      "|    std                | 13.8          |\n",
      "|    value_loss         | 4.81e-06      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 930          |\n",
      "|    iterations         | 6400         |\n",
      "|    time_elapsed       | 34           |\n",
      "|    total_timesteps    | 32000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -61.2        |\n",
      "|    explained_variance | -4.34        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6399         |\n",
      "|    policy_loss        | -3.73        |\n",
      "|    reward             | -0.009264551 |\n",
      "|    std                | 14.4         |\n",
      "|    value_loss         | 0.0103       |\n",
      "----------------------------------------\n",
      "Episode: 39\n",
      "day: 1112, episode: 39\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 926489.36\n",
      "total_reward: -73510.64\n",
      "total_cost: 83384.46\n",
      "total_trades: 7631\n",
      "Sharpe: -0.164\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 930          |\n",
      "|    iterations         | 6500         |\n",
      "|    time_elapsed       | 34           |\n",
      "|    total_timesteps    | 32500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -61.8        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6499         |\n",
      "|    policy_loss        | -0.277       |\n",
      "|    reward             | -0.004840626 |\n",
      "|    std                | 15.1         |\n",
      "|    value_loss         | 3e-05        |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 929           |\n",
      "|    iterations         | 6600          |\n",
      "|    time_elapsed       | 35            |\n",
      "|    total_timesteps    | 33000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -62.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6599          |\n",
      "|    policy_loss        | -0.587        |\n",
      "|    reward             | -0.0052276864 |\n",
      "|    std                | 15.9          |\n",
      "|    value_loss         | 0.000166      |\n",
      "-----------------------------------------\n",
      "Episode: 40\n",
      "day: 1112, episode: 40\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 832649.46\n",
      "total_reward: -167350.54\n",
      "total_cost: 86967.33\n",
      "total_trades: 8093\n",
      "Sharpe: -0.350\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 930          |\n",
      "|    iterations         | 6700         |\n",
      "|    time_elapsed       | 36           |\n",
      "|    total_timesteps    | 33500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -63.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6699         |\n",
      "|    policy_loss        | 0.0949       |\n",
      "|    reward             | -0.013743795 |\n",
      "|    std                | 16.5         |\n",
      "|    value_loss         | 2.72e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 6800          |\n",
      "|    time_elapsed       | 36            |\n",
      "|    total_timesteps    | 34000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -63.9         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 6799          |\n",
      "|    policy_loss        | 0.108         |\n",
      "|    reward             | -0.0035603002 |\n",
      "|    std                | 17.3          |\n",
      "|    value_loss         | 1.2e-05       |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 930          |\n",
      "|    iterations         | 6900         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 34500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.3        |\n",
      "|    explained_variance | -15.3        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6899         |\n",
      "|    policy_loss        | 1.07         |\n",
      "|    reward             | -0.019406997 |\n",
      "|    std                | 17.8         |\n",
      "|    value_loss         | 0.00113      |\n",
      "----------------------------------------\n",
      "Episode: 41\n",
      "day: 1112, episode: 41\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 753394.49\n",
      "total_reward: -246605.51\n",
      "total_cost: 94879.49\n",
      "total_trades: 8543\n",
      "Sharpe: -0.473\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 930          |\n",
      "|    iterations         | 7000         |\n",
      "|    time_elapsed       | 37           |\n",
      "|    total_timesteps    | 35000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -64.8        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 6999         |\n",
      "|    policy_loss        | -0.046       |\n",
      "|    reward             | -0.005407518 |\n",
      "|    std                | 18.4         |\n",
      "|    value_loss         | 7.99e-06     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 7100          |\n",
      "|    time_elapsed       | 38            |\n",
      "|    total_timesteps    | 35500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -65.4         |\n",
      "|    explained_variance | -4.31e+03     |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7099          |\n",
      "|    policy_loss        | 19.8          |\n",
      "|    reward             | -0.0043732147 |\n",
      "|    std                | 19.2          |\n",
      "|    value_loss         | 0.289         |\n",
      "-----------------------------------------\n",
      "Episode: 42\n",
      "day: 1112, episode: 42\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 735306.87\n",
      "total_reward: -264693.13\n",
      "total_cost: 105419.68\n",
      "total_trades: 9001\n",
      "Sharpe: -0.425\n",
      "=================================\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 930         |\n",
      "|    iterations         | 7200        |\n",
      "|    time_elapsed       | 38          |\n",
      "|    total_timesteps    | 36000       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -65.9       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 7199        |\n",
      "|    policy_loss        | 0.123       |\n",
      "|    reward             | -0.00550439 |\n",
      "|    std                | 19.9        |\n",
      "|    value_loss         | 8.77e-06    |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 7300          |\n",
      "|    time_elapsed       | 39            |\n",
      "|    total_timesteps    | 36500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -66.4         |\n",
      "|    explained_variance | -1.22         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7299          |\n",
      "|    policy_loss        | 0.769         |\n",
      "|    reward             | -0.0133272465 |\n",
      "|    std                | 20.5          |\n",
      "|    value_loss         | 0.000232      |\n",
      "-----------------------------------------\n",
      "Episode: 43\n",
      "day: 1112, episode: 43\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 845765.01\n",
      "total_reward: -154234.99\n",
      "total_cost: 101209.05\n",
      "total_trades: 8819\n",
      "Sharpe: -0.187\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 930           |\n",
      "|    iterations         | 7400          |\n",
      "|    time_elapsed       | 39            |\n",
      "|    total_timesteps    | 37000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -66.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7399          |\n",
      "|    policy_loss        | 0.32          |\n",
      "|    reward             | -0.0112108495 |\n",
      "|    std                | 21.1          |\n",
      "|    value_loss         | 3.93e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 931          |\n",
      "|    iterations         | 7500         |\n",
      "|    time_elapsed       | 40           |\n",
      "|    total_timesteps    | 37500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -67.3        |\n",
      "|    explained_variance | -3.45        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7499         |\n",
      "|    policy_loss        | -1.84        |\n",
      "|    reward             | -0.015472357 |\n",
      "|    std                | 21.7         |\n",
      "|    value_loss         | 0.00096      |\n",
      "----------------------------------------\n",
      "Episode: 44\n",
      "day: 1112, episode: 44\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 752152.86\n",
      "total_reward: -247847.14\n",
      "total_cost: 96917.85\n",
      "total_trades: 8723\n",
      "Sharpe: -0.346\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 931           |\n",
      "|    iterations         | 7600          |\n",
      "|    time_elapsed       | 40            |\n",
      "|    total_timesteps    | 38000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -67.6         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7599          |\n",
      "|    policy_loss        | 0.279         |\n",
      "|    reward             | -0.0037972888 |\n",
      "|    std                | 22.2          |\n",
      "|    value_loss         | 2.69e-05      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 931          |\n",
      "|    iterations         | 7700         |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 38500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7699         |\n",
      "|    policy_loss        | 0.131        |\n",
      "|    reward             | -0.009364438 |\n",
      "|    std                | 23           |\n",
      "|    value_loss         | 1.78e-05     |\n",
      "----------------------------------------\n",
      "Episode: 45\n",
      "day: 1112, episode: 45\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1018051.48\n",
      "total_reward: 18051.48\n",
      "total_cost: 113821.56\n",
      "total_trades: 9208\n",
      "Sharpe: 0.091\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 931          |\n",
      "|    iterations         | 7800         |\n",
      "|    time_elapsed       | 41           |\n",
      "|    total_timesteps    | 39000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -68.6        |\n",
      "|    explained_variance | -1.19e-07    |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7799         |\n",
      "|    policy_loss        | 0.232        |\n",
      "|    reward             | -0.012396053 |\n",
      "|    std                | 23.7         |\n",
      "|    value_loss         | 1.9e-05      |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 7900         |\n",
      "|    time_elapsed       | 42           |\n",
      "|    total_timesteps    | 39500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -69.1        |\n",
      "|    explained_variance | -34.8        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 7899         |\n",
      "|    policy_loss        | 2.82         |\n",
      "|    reward             | -0.010228097 |\n",
      "|    std                | 24.5         |\n",
      "|    value_loss         | 0.00248      |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 932           |\n",
      "|    iterations         | 8000          |\n",
      "|    time_elapsed       | 42            |\n",
      "|    total_timesteps    | 40000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.4         |\n",
      "|    explained_variance | -10.4         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 7999          |\n",
      "|    policy_loss        | -0.985        |\n",
      "|    reward             | -0.0071696695 |\n",
      "|    std                | 25.2          |\n",
      "|    value_loss         | 0.000318      |\n",
      "-----------------------------------------\n",
      "Episode: 46\n",
      "day: 1112, episode: 46\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 727717.31\n",
      "total_reward: -272282.69\n",
      "total_cost: 100039.35\n",
      "total_trades: 9013\n",
      "Sharpe: -0.326\n",
      "=================================\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 932           |\n",
      "|    iterations         | 8100          |\n",
      "|    time_elapsed       | 43            |\n",
      "|    total_timesteps    | 40500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -69.9         |\n",
      "|    explained_variance | -1.47         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8099          |\n",
      "|    policy_loss        | 0.697         |\n",
      "|    reward             | -0.0062329704 |\n",
      "|    std                | 26            |\n",
      "|    value_loss         | 0.000135      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 932           |\n",
      "|    iterations         | 8200          |\n",
      "|    time_elapsed       | 43            |\n",
      "|    total_timesteps    | 41000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -70.5         |\n",
      "|    explained_variance | -0.185        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8199          |\n",
      "|    policy_loss        | 0.775         |\n",
      "|    reward             | -0.0103025315 |\n",
      "|    std                | 27            |\n",
      "|    value_loss         | 0.00014       |\n",
      "-----------------------------------------\n",
      "Episode: 47\n",
      "day: 1112, episode: 47\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 938940.46\n",
      "total_reward: -61059.54\n",
      "total_cost: 110828.02\n",
      "total_trades: 9559\n",
      "Sharpe: -0.077\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 8300         |\n",
      "|    time_elapsed       | 44           |\n",
      "|    total_timesteps    | 41500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -71.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8299         |\n",
      "|    policy_loss        | 0.256        |\n",
      "|    reward             | -0.006578839 |\n",
      "|    std                | 28.1         |\n",
      "|    value_loss         | 1.41e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 932           |\n",
      "|    iterations         | 8400          |\n",
      "|    time_elapsed       | 45            |\n",
      "|    total_timesteps    | 42000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -71.8         |\n",
      "|    explained_variance | 0             |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 8399          |\n",
      "|    policy_loss        | 0.915         |\n",
      "|    reward             | -0.0037822938 |\n",
      "|    std                | 29.6          |\n",
      "|    value_loss         | 0.000189      |\n",
      "-----------------------------------------\n",
      "Episode: 48\n",
      "day: 1112, episode: 48\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 882337.48\n",
      "total_reward: -117662.52\n",
      "total_cost: 116038.53\n",
      "total_trades: 9790\n",
      "Sharpe: -0.180\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 8500         |\n",
      "|    time_elapsed       | 45           |\n",
      "|    total_timesteps    | 42500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -72.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8499         |\n",
      "|    policy_loss        | 0.577        |\n",
      "|    reward             | -0.006764283 |\n",
      "|    std                | 30.7         |\n",
      "|    value_loss         | 8.38e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 8600         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 43000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73          |\n",
      "|    explained_variance | 0.748        |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8599         |\n",
      "|    policy_loss        | 0.222        |\n",
      "|    reward             | -0.013122176 |\n",
      "|    std                | 32           |\n",
      "|    value_loss         | 3.99e-05     |\n",
      "----------------------------------------\n",
      "Episode: 49\n",
      "day: 1112, episode: 49\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 869145.39\n",
      "total_reward: -130854.61\n",
      "total_cost: 125367.52\n",
      "total_trades: 10240\n",
      "Sharpe: -0.151\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 8700         |\n",
      "|    time_elapsed       | 46           |\n",
      "|    total_timesteps    | 43500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.3        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8699         |\n",
      "|    policy_loss        | -0.567       |\n",
      "|    reward             | -0.012616987 |\n",
      "|    std                | 32.8         |\n",
      "|    value_loss         | 7.52e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 8800         |\n",
      "|    time_elapsed       | 47           |\n",
      "|    total_timesteps    | 44000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -73.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8799         |\n",
      "|    policy_loss        | 1.16         |\n",
      "|    reward             | -0.009087533 |\n",
      "|    std                | 34.1         |\n",
      "|    value_loss         | 0.000289     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 932         |\n",
      "|    iterations         | 8900        |\n",
      "|    time_elapsed       | 47          |\n",
      "|    total_timesteps    | 44500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -74.5       |\n",
      "|    explained_variance | -1.19e-07   |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 8899        |\n",
      "|    policy_loss        | 0.625       |\n",
      "|    reward             | -0.02127541 |\n",
      "|    std                | 35.5        |\n",
      "|    value_loss         | 0.000104    |\n",
      "---------------------------------------\n",
      "Episode: 50\n",
      "day: 1112, episode: 50\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 999471.17\n",
      "total_reward: -528.83\n",
      "total_cost: 126041.98\n",
      "total_trades: 9983\n",
      "Sharpe: 0.043\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 9000         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 45000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.1        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 8999         |\n",
      "|    policy_loss        | 0.279        |\n",
      "|    reward             | -0.016512575 |\n",
      "|    std                | 36.9         |\n",
      "|    value_loss         | 2.36e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 9100         |\n",
      "|    time_elapsed       | 48           |\n",
      "|    total_timesteps    | 45500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -75.7        |\n",
      "|    explained_variance | 1.19e-07     |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9099         |\n",
      "|    policy_loss        | 0.859        |\n",
      "|    reward             | -0.013858461 |\n",
      "|    std                | 38.6         |\n",
      "|    value_loss         | 0.000215     |\n",
      "----------------------------------------\n",
      "Episode: 51\n",
      "day: 1112, episode: 51\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 909289.86\n",
      "total_reward: -90710.14\n",
      "total_cost: 131459.89\n",
      "total_trades: 10520\n",
      "Sharpe: -0.171\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 9200         |\n",
      "|    time_elapsed       | 49           |\n",
      "|    total_timesteps    | 46000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -76.4        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9199         |\n",
      "|    policy_loss        | 0.845        |\n",
      "|    reward             | -0.008928339 |\n",
      "|    std                | 40.3         |\n",
      "|    value_loss         | 0.000128     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 932         |\n",
      "|    iterations         | 9300        |\n",
      "|    time_elapsed       | 49          |\n",
      "|    total_timesteps    | 46500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -77.1       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9299        |\n",
      "|    policy_loss        | 0.472       |\n",
      "|    reward             | -0.05192639 |\n",
      "|    std                | 42.3        |\n",
      "|    value_loss         | 0.000103    |\n",
      "---------------------------------------\n",
      "Episode: 52\n",
      "day: 1112, episode: 52\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 993426.80\n",
      "total_reward: -6573.20\n",
      "total_cost: 139825.00\n",
      "total_trades: 11099\n",
      "Sharpe: 0.058\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 9400         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 47000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -77.6        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9399         |\n",
      "|    policy_loss        | 0.536        |\n",
      "|    reward             | -0.007911962 |\n",
      "|    std                | 43.8         |\n",
      "|    value_loss         | 5.07e-05     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 9500         |\n",
      "|    time_elapsed       | 50           |\n",
      "|    total_timesteps    | 47500        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.2        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9499         |\n",
      "|    policy_loss        | 0.952        |\n",
      "|    reward             | -0.020255381 |\n",
      "|    std                | 45.6         |\n",
      "|    value_loss         | 0.000164     |\n",
      "----------------------------------------\n",
      "Episode: 53\n",
      "day: 1112, episode: 53\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1048388.15\n",
      "total_reward: 48388.15\n",
      "total_cost: 145083.27\n",
      "total_trades: 11238\n",
      "Sharpe: 0.150\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 932          |\n",
      "|    iterations         | 9600         |\n",
      "|    time_elapsed       | 51           |\n",
      "|    total_timesteps    | 48000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -78.8        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9599         |\n",
      "|    policy_loss        | 1.77         |\n",
      "|    reward             | -0.010137132 |\n",
      "|    std                | 47.4         |\n",
      "|    value_loss         | 0.000574     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| time/                 |             |\n",
      "|    fps                | 932         |\n",
      "|    iterations         | 9700        |\n",
      "|    time_elapsed       | 51          |\n",
      "|    total_timesteps    | 48500       |\n",
      "| train/                |             |\n",
      "|    entropy_loss       | -79.4       |\n",
      "|    explained_variance | 0           |\n",
      "|    learning_rate      | 0.0007      |\n",
      "|    n_updates          | 9699        |\n",
      "|    policy_loss        | -0.239      |\n",
      "|    reward             | -0.01265401 |\n",
      "|    std                | 49.4        |\n",
      "|    value_loss         | 3.38e-05    |\n",
      "---------------------------------------\n",
      "Episode: 54\n",
      "day: 1112, episode: 54\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1188648.01\n",
      "total_reward: 188648.01\n",
      "total_cost: 154903.74\n",
      "total_trades: 11595\n",
      "Sharpe: 0.348\n",
      "=================================\n",
      "----------------------------------------\n",
      "| time/                 |              |\n",
      "|    fps                | 933          |\n",
      "|    iterations         | 9800         |\n",
      "|    time_elapsed       | 52           |\n",
      "|    total_timesteps    | 49000        |\n",
      "| train/                |              |\n",
      "|    entropy_loss       | -79.9        |\n",
      "|    explained_variance | 0            |\n",
      "|    learning_rate      | 0.0007       |\n",
      "|    n_updates          | 9799         |\n",
      "|    policy_loss        | 0.649        |\n",
      "|    reward             | -0.009685895 |\n",
      "|    std                | 51.4         |\n",
      "|    value_loss         | 6.39e-05     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 932           |\n",
      "|    iterations         | 9900          |\n",
      "|    time_elapsed       | 53            |\n",
      "|    total_timesteps    | 49500         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -80.5         |\n",
      "|    explained_variance | -0.432        |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9899          |\n",
      "|    policy_loss        | 0.886         |\n",
      "|    reward             | -0.0132708065 |\n",
      "|    std                | 53.4          |\n",
      "|    value_loss         | 0.000129      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                 |               |\n",
      "|    fps                | 932           |\n",
      "|    iterations         | 10000         |\n",
      "|    time_elapsed       | 53            |\n",
      "|    total_timesteps    | 50000         |\n",
      "| train/                |               |\n",
      "|    entropy_loss       | -81           |\n",
      "|    explained_variance | 0.183         |\n",
      "|    learning_rate      | 0.0007        |\n",
      "|    n_updates          | 9999          |\n",
      "|    policy_loss        | 0.0396        |\n",
      "|    reward             | -0.0113941515 |\n",
      "|    std                | 55.1          |\n",
      "|    value_loss         | 2.08e-05      |\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## A2C\n",
    "\n",
    "agent = DRLAgent(env=env_train)\n",
    "model_a2c = agent.get_model(\"a2c\")\n",
    "\n",
    "trained_a2c = agent.train_model(\n",
    "    model=model_a2c, tb_log_name=\"a2c\", total_timesteps=50000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc66935-c07d-47db-94f1-a4b13b7dfb6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b92292b-febf-4c19-b127-8e4986f89a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b218b9b-1ddf-41ea-b83e-7d7ce73932b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2\n",
      "day: 103, episode: 2\n",
      "begin_total_asset: 1000000.00\n",
      "end_total_asset: 1291942.34\n",
      "total_reward: 291942.34\n",
      "total_cost: 68.66\n",
      "total_trades: 39\n",
      "Sharpe: 3.370\n",
      "=================================\n",
      "hit end!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>600000.SH</th>\n",
       "      <th>600009.SH</th>\n",
       "      <th>600016.SH</th>\n",
       "      <th>600028.SH</th>\n",
       "      <th>600030.SH</th>\n",
       "      <th>600031.SH</th>\n",
       "      <th>600036.SH</th>\n",
       "      <th>600050.SH</th>\n",
       "      <th>600104.SH</th>\n",
       "      <th>600196.SH</th>\n",
       "      <th>600276.SH</th>\n",
       "      <th>600309.SH</th>\n",
       "      <th>600519.SH</th>\n",
       "      <th>600547.SH</th>\n",
       "      <th>600570.SH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-02</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-05</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-06</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-24</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-25</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-30</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>103 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            600000.SH  600009.SH  600016.SH  600028.SH  600030.SH  600031.SH  \\\n",
       "date                                                                           \n",
       "2019-08-01          0          0       1000       1000          0       1000   \n",
       "2019-08-01          0          0       1000       1000          0       1000   \n",
       "2019-08-02          0          0       1000       1000          0       1000   \n",
       "2019-08-05          0          0       1000       1000          0       1000   \n",
       "2019-08-06          0          0       1000       1000          0       1000   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-12-24          0          0          0          0          0          0   \n",
       "2019-12-25          0          0          0          0          0          0   \n",
       "2019-12-26          0          0          0          0          0          0   \n",
       "2019-12-27          0          0          0          0          0          0   \n",
       "2019-12-30          0          0          0          0          0          0   \n",
       "\n",
       "            600036.SH  600050.SH  600104.SH  600196.SH  600276.SH  600309.SH  \\\n",
       "date                                                                           \n",
       "2019-08-01          0          0          0          0       1000       1000   \n",
       "2019-08-01          0          0          0          0       1000       1000   \n",
       "2019-08-02          0          0          0          0       1000       1000   \n",
       "2019-08-05          0          0          0          0       1000       1000   \n",
       "2019-08-06          0          0          0          0       1000       1000   \n",
       "...               ...        ...        ...        ...        ...        ...   \n",
       "2019-12-24          0          0          0          0          0          0   \n",
       "2019-12-25          0          0          0          0          0          0   \n",
       "2019-12-26          0          0          0          0          0          0   \n",
       "2019-12-27          0          0          0          0          0          0   \n",
       "2019-12-30          0          0          0          0          0          0   \n",
       "\n",
       "            600519.SH  600547.SH  600570.SH  \n",
       "date                                         \n",
       "2019-08-01          0          0          0  \n",
       "2019-08-01          0          0          0  \n",
       "2019-08-02          0          0          0  \n",
       "2019-08-05          0          0          0  \n",
       "2019-08-06          0          0          0  \n",
       "...               ...        ...        ...  \n",
       "2019-12-24          0          0          0  \n",
       "2019-12-25          0          0          0  \n",
       "2019-12-26          0          0          0  \n",
       "2019-12-27          0          0          0  \n",
       "2019-12-30          0          0          0  \n",
       "\n",
       "[103 rows x 15 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Trade\n",
    "\n",
    "trade = p.data_split(p.dataframe, TRADE_START_DATE, TRADE_END_DATE)\n",
    "trade[\"date\"] = trade.time\n",
    "\n",
    "env_kwargs = {\n",
    "    \"stock_dim\": stock_dimension,\n",
    "    \"hmax\": 1000,\n",
    "    \"initial_amount\": 1000000,\n",
    "    \"buy_cost_pct\": 6.87e-5,\n",
    "    \"sell_cost_pct\": 1.0687e-3,\n",
    "    \"reward_scaling\": 1e-4,\n",
    "    \"state_space\": state_space,\n",
    "    \"action_space\": stock_dimension,\n",
    "    \"tech_indicator_list\": config.INDICATORS,\n",
    "    \"print_verbosity\": 1,\n",
    "    \"initial_buy\": False,\n",
    "    \"hundred_each_trade\": True,\n",
    "}\n",
    "e_trade_gym = StockTradingEnv(df=trade, **env_kwargs)\n",
    "\n",
    "df_account_value, df_actions = DRLAgent.DRL_prediction(\n",
    "    model=trained_ddpg, environment=e_trade_gym\n",
    ")\n",
    "\n",
    "df_actions.to_csv(\"action.csv\", index=False)\n",
    "df_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5ae09-f3ed-4623-a9bb-bfd5f93c8eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8e9dacbc-2963-4561-a4f5-7fb4c4d490f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m \u001b[0mReturnPlotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_account_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_trade\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "An easy-to-use plotting tool to plot cumulative returns over time.\n",
       "Baseline supports equal weighting(default) and any stocks you want to use for comparison.\n",
       "\u001b[0;31mFile:\u001b[0m           ~/Desktop/FinRL-Meta-master/meta/data_processors/tushare.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ReturnPlotter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b91863d-001b-42ed-ac00-6af2ff42f8d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "912eb743-8673-4cbf-92c4-e4dc530b7c18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (103,) and (104,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m plotter \u001b[38;5;241m=\u001b[39m ReturnPlotter(df_account_value, trade, TRADE_START_DATE, TRADE_END_DATE)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# plotter.plot_all()\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mplotter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# matplotlib inline\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# # ticket: SSE 50：000016\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# plotter.plot(\"000016\")\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/FinRL-Meta-master/meta/data_processors/tushare.py:226\u001b[0m, in \u001b[0;36mReturnPlotter.plot\u001b[0;34m(self, baseline_ticket)\u001b[0m\n\u001b[1;32m    224\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCumulative Returns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    225\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(time, ours, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDDPG Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgreen\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 226\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_label\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m plt\u001b[38;5;241m.\u001b[39mxticks([i \u001b[38;5;241m*\u001b[39m days_per_tick \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(ticks))], ticks, fontsize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m    229\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml11/lib/python3.11/site-packages/matplotlib/pyplot.py:3827\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3819\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   3820\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mplot\u001b[39m(\n\u001b[1;32m   3821\u001b[0m     \u001b[38;5;241m*\u001b[39margs: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m ArrayLike \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3825\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3826\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mlist\u001b[39m[Line2D]:\n\u001b[0;32m-> 3827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3828\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml11/lib/python3.11/site-packages/matplotlib/axes/_axes.py:1777\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1535\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1536\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1776\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1777\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1778\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml11/lib/python3.11/site-packages/matplotlib/axes/_base.py:297\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, axes, data, return_kwargs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    296\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 297\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_kwargs\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml11/lib/python3.11/site-packages/matplotlib/axes/_base.py:494\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, axes, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    491\u001b[0m     axes\u001b[38;5;241m.\u001b[39myaxis\u001b[38;5;241m.\u001b[39mupdate_units(y)\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 494\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    495\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y can be no greater than 2D, but have \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    498\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (103,) and (104,)"
     ]
    }
   ],
   "source": [
    "### Backtest\n",
    "\n",
    "# matplotlib inline\n",
    "df_account_value[\"time\"] = df_account_value.date\n",
    "plotter = ReturnPlotter(df_account_value, trade, TRADE_START_DATE, TRADE_END_DATE)\n",
    "# plotter.plot_all()\n",
    "\n",
    "plotter.plot()\n",
    "\n",
    "# matplotlib inline\n",
    "# # ticket: SSE 50：000016\n",
    "# plotter.plot(\"000016\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a13dc1ec-a4b8-43c6-b0b2-6429035e0f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time\n",
       "2019-08-01    1\n",
       "2019-11-08    1\n",
       "2019-11-22    1\n",
       "2019-11-21    1\n",
       "2019-11-20    1\n",
       "             ..\n",
       "2019-09-16    1\n",
       "2019-09-12    1\n",
       "2019-09-11    1\n",
       "2019-09-10    1\n",
       "2019-12-31    1\n",
       "Name: count, Length: 103, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_account_value.time.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c342767-a399-48be-8709-182e7d5acc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d5cc8-d8c0-48ee-a4a7-f490fb92d932",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ecd7b90a-fd32-4b6b-b11a-e714b2ae9bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本接口即将停止更新，请尽快使用Pro版接口：https://tushare.pro/document/2\n",
      "Remote end closed connection without response\n",
      "Remote end closed connection without response\n",
      "Remote end closed connection without response\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "获取失败，请检查网络.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#### Use pyfolio\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# CSI 300\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m baseline_df \u001b[38;5;241m=\u001b[39m \u001b[43mplotter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_baseline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m399300\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m daily_return \u001b[38;5;241m=\u001b[39m plotter\u001b[38;5;241m.\u001b[39mget_return(df_account_value)\n\u001b[1;32m      8\u001b[0m daily_return_base \u001b[38;5;241m=\u001b[39m plotter\u001b[38;5;241m.\u001b[39mget_return(baseline_df, value_col_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/FinRL-Meta-master/meta/data_processors/tushare.py:178\u001b[0m, in \u001b[0;36mReturnPlotter.get_baseline\u001b[0;34m(self, ticket)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_baseline\u001b[39m(\u001b[38;5;28mself\u001b[39m, ticket):\n\u001b[0;32m--> 178\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mts\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_hist_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m     df\u001b[38;5;241m.\u001b[39mloc[:, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mindex\n\u001b[1;32m    180\u001b[0m     df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml11/lib/python3.11/site-packages/tushare/stock/trading.py:104\u001b[0m, in \u001b[0;36mget_hist_data\u001b[0;34m(code, start, end, ktype, retry_count, pause)\u001b[0m\n\u001b[1;32m    102\u001b[0m         df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39msort_index(ascending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(ct\u001b[38;5;241m.\u001b[39mNETWORK_URL_ERROR_MSG)\n",
      "\u001b[0;31mOSError\u001b[0m: 获取失败，请检查网络."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#### Use pyfolio\n",
    "\n",
    "# CSI 300\n",
    "baseline_df = plotter.get_baseline(\"399300\")\n",
    "\n",
    "\n",
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(\n",
    "    returns=daily_return,\n",
    "    factor_returns=daily_return_base,\n",
    "    positions=None,\n",
    "    transactions=None,\n",
    "    turnover_denom=\"AGB\",\n",
    ")\n",
    "print(\"==============DRL Strategy Stats===========\")\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")\n",
    "\n",
    "\n",
    "daily_return = plotter.get_return(df_account_value)\n",
    "daily_return_base = plotter.get_return(baseline_df, value_col_name=\"close\")\n",
    "\n",
    "perf_func = timeseries.perf_stats\n",
    "perf_stats_all = perf_func(\n",
    "    returns=daily_return_base,\n",
    "    factor_returns=daily_return_base,\n",
    "    positions=None,\n",
    "    transactions=None,\n",
    "    turnover_denom=\"AGB\",\n",
    ")\n",
    "print(\"==============Baseline Strategy Stats===========\")\n",
    "\n",
    "print(f\"perf_stats_all: {perf_stats_all}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1c394c-9f56-473b-87f3-4c5e7e2dacaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd3e194-2884-4434-9505-d4b5b6c34663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4de1e7-8e69-4726-b260-032c8d0cbe48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5998af15-409f-4240-b4db-7a3d67e86b5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e59a7a-b570-44c2-bffe-f5161b3ddf69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

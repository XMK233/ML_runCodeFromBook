{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 图像分割算法演示\n",
    "\n",
    "本Notebook演示如何使用基于UNet架构的图像分割算法进行图像分割任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'WenQuanYi Micro Hei', 'Heiti TC']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f"使用设备: {device}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 定义UNet模型架构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义UNet架构中的基本构建块\n",
    "class DoubleConv(nn.Module):\n",
    "    \"""两次卷积操作（Conv2d -> BatchNorm -> ReLU）的组合\"""\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "# 定义UNet架构\n",
    "class UNet(nn.Module):\n",
    "    \"""基于经典UNet架构的图像分割模型\"""\n",
    "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256, 512]):\n",
    "        super(UNet, self).__init__()\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        # 下采样路径（编码器）\n",
    "        for feature in features:\n",
    "            self.downs.append(DoubleConv(in_channels, feature))\n",
    "            in_channels = feature\n",
    "        \n",
    "        # 上采样路径（解码器）\n",
    "        for feature in reversed(features):\n",
    "            self.ups.append(\n",
    "                nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2)\n",
    "            )\n",
    "            self.ups.append(DoubleConv(feature*2, feature))\n",
    "        \n",
    "        # 瓶颈层\n",
    "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
    "        \n",
    "        # 输出层\n",
    "        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        skip_connections = []\n",
    "        \n",
    "        # 下采样过程，保存跳跃连接\n",
    "        for down in self.downs:\n",
    "            x = down(x)\n",
    "            skip_connections.append(x)\n",
    "            x = self.pool(x)\n",
    "        \n",
    "        # 瓶颈层\n",
    "        x = self.bottleneck(x)\n",
    "        \n",
    "        # 反转跳跃连接列表，以便在解码器中使用\n",
    "        skip_connections = skip_connections[::-1]\n",
    "        \n",
    "        # 上采样过程，结合跳跃连接\n",
    "        for idx in range(0, len(self.ups), 2):\n",
    "            x = self.ups[idx](x)\n",
    "            skip_connection = skip_connections[idx//2]\n",
    "            \n",
    "            # 如果输入尺寸不匹配，调整跳跃连接的尺寸\n",
    "            if x.shape != skip_connection.shape:\n",
    "                x = F.interpolate(x, size=skip_connection.shape[2:], mode=\"bilinear\", align_corners=True)\n",
    "            \n",
    "            # 连接特征图\n",
    "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
    "            x = self.ups[idx+1](concat_skip)\n",
    "        \n",
    "        # 输出分割图\n",
    "        return self.final_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 数据处理和加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义数据集类\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx].replace(\"image\", \"mask\"))\n",
    "        \n",
    "        # 加载图像和掩码\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        mask = Image.open(mask_path).convert(\"L\")  # 转为灰度图\n",
    "        \n",
    "        # 应用变换\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "            mask = (mask > 0.5).float()  # 二值化\n",
    "        \n",
    "        return image, mask\n",
    "\n",
    "# 定义数据变换\n",
    "def get_transforms(img_size=(256, 256)):\n",
    "    train_transforms = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomVerticalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    val_transforms = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    return train_transforms, val_transforms" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 创建演示数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个简单的演示数据集\n",
    "def create_demo_dataset():\n",
    "    \"""创建一个简单的演示数据集用于测试图像分割算法\"""\n",
    "    # 设置数据路径\n",
    "    BASE_PATH = os.path.dirname(os.path.abspath('.'))\n",
    "    DATA_PATH = os.path.join(BASE_PATH, "segmentation_data")\n",
    "    os.makedirs(DATA_PATH, exist_ok=True)\n",
    "    \n",
    "    # 创建数据集文件夹\n",
    "    demo_image_dir = os.path.join(DATA_PATH, "demo_images")\n",
    "    demo_mask_dir = os.path.join(DATA_PATH, "demo_masks")\n",
    "    os.makedirs(demo_image_dir, exist_ok=True)\n",
    "    os.makedirs(demo_mask_dir, exist_ok=True)\n",
    "    \n",
    "    # 创建一些简单的图像和对应的掩码\n",
    "    for i in range(20):\n",
    "        # 创建随机彩色图像\n",
    "        image = np.random.randint(0, 256, (256, 256, 3), dtype=np.uint8)\n",
    "        \n",
    "        # 创建对应的掩码（圆形）\n",
    "        mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "        center_x, center_y = np.random.randint(64, 192, 2)\n",
    "        radius = np.random.randint(32, 64)\n",
    "        \n",
    "        y, x = np.ogrid[:256, :256]\n",
    "        distance = np.sqrt((x - center_x)**2 + (y - center_y)** 2)\n",
    "        mask[distance <= radius] = 255\n",
    "        \n",
    "        # 保存图像和掩码\n",
    "        Image.fromarray(image).save(os.path.join(demo_image_dir, f"image_{i}.png"))\n",
    "        Image.fromarray(mask).save(os.path.join(demo_mask_dir, f"mask_{i}.png"))\n",
    "    \n",
    "    print(f"演示数据集已创建，包含20张图像和对应的掩码")\n",
    "    return demo_image_dir, demo_mask_dir\n",
    "\n",
    "# 创建演示数据集\n",
    "image_dir, mask_dir = create_demo_dataset()\n",
    "\n",
    "# 获取数据变换\n",
    "train_transforms, val_transforms = get_transforms(img_size=(256, 256))\n",
    "\n",
    "# 创建数据集和数据加载器\n",
    "# 简单划分训练集和验证集（80%训练，20%验证）\n",
    "all_images = os.listdir(image_dir)\n",
    "train_size = int(0.8 * len(all_images))\n",
    "\n",
    "train_dataset = SegmentationDataset(\n",
    "    image_dir=image_dir,\n",
    "    mask_dir=mask_dir,\n",
    "    transform=train_transforms\n",
    ")\n",
    "\n",
    "val_dataset = SegmentationDataset(\n",
    "    image_dir=image_dir,\n",
    "    mask_dir=mask_dir,\n",
    "    transform=val_transforms\n",
    ")\n",
    "\n",
    "# 使用随机采样器划分数据集\n",
    "train_indices = torch.randperm(len(train_dataset))[:train_size]\n",
    "val_indices = torch.randperm(len(val_dataset))[train_size:]\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    sampler=train_sampler,\n",
    "    num_workers=0  # 在Jupyter中通常设为0以避免多进程问题\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    sampler=val_sampler,\n",
    "    num_workers=0\n",
    ")" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 定义评估指标和训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义IoU（Intersection over Union）指标计算函数\n",
    "def calculate_iou(pred, target, threshold=0.5):\n",
    "    pred = (pred > threshold).float()\n",
    "    intersection = torch.sum(pred * target)\n",
    "    union = torch.sum(pred) + torch.sum(target) - intersection\n",
    "    \n",
    "    if union == 0:\n",
    "        return 0.0  # 避免除以零\n",
    "    \n",
    "    return intersection / union\n",
    "\n",
    "# 定义训练函数\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, num_epochs=10, patience=3):\n",
    "    best_val_iou = 0.0\n",
    "    early_stopping_counter = 0\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_ious = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # 训练阶段\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, masks in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} - 训练"):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            # 前向传播\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            # 反向传播和优化\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_loss / len(train_loader.dataset)\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        running_val_loss = 0.0\n",
    "        running_val_iou = 0.0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, masks in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} - 验证"):\n",
    "                images, masks = images.to(device), masks.to(device)\n",
    "                \n",
    "                # 前向传播\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                # 计算IoU\n",
    "                iou = calculate_iou(outputs, masks)\n",
    "                \n",
    "                running_val_loss += loss.item() * images.size(0)\n",
    "                running_val_iou += iou * images.size(0)\n",
    "        \n",
    "        epoch_val_loss = running_val_loss / len(val_loader.dataset)\n",
    "        epoch_val_iou = running_val_iou / len(val_loader.dataset)\n",
    "        \n",
    "        val_losses.append(epoch_val_loss)\n",
    "        val_ious.append(epoch_val_iou)\n",
    "        \n",
    "        print(f"Epoch {epoch+1}/{num_epochs}:")\n",
    "        print(f"  训练损失: {epoch_train_loss:.4f}")\n",
    "        print(f"  验证损失: {epoch_val_loss:.4f}")\n",
    "        print(f"  验证IoU: {epoch_val_iou:.4f}")\n",
    "        \n",
    "        # 早停机制\n",
    "        if epoch_val_iou > best_val_iou:\n",
    "            best_val_iou = epoch_val_iou\n",
    "            torch.save(model.state_dict(), \")\n",
    "                os.path.join(os.path.dirname(os.path.abspath('.')), \")\n",
    "                "segmentation_models", "best_unet_model.pth")\n",
    "            early_stopping_counter = 0\n",
    "            print(f"  模型已保存，最佳IoU: {best_val_iou:.4f}")\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "            print(f"  早停计数器: {early_stopping_counter}/{patience}")\n",
    "            \n",
    "            if early_stopping_counter >= patience:\n",
    "                print("早停机制触发，停止训练")\n",
    "                break\n",
    "    \n",
    "    # 绘制训练过程图表\n",
    "    plot_training_history(train_losses, val_losses, val_ious)\n",
    "    \n",
    "    return model\n",
    "\n",
    "# 绘制训练历史图表\n",
    "def plot_training_history(train_losses, val_losses, val_ious):\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # 绘制损失曲线\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='训练损失')\n",
    "    plt.plot(val_losses, label='验证损失')\n",
    "    plt.title('训练和验证损失')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('损失')\n",
    "    plt.legend()\n",
    "    \n",
    "    # 绘制IoU曲线\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_ious, label='验证IoU')\n",
    "    plt.title('验证IoU')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('IoU')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型\n",
    "model = UNet(in_channels=3, out_channels=1, features=[64, 128, 256, 512]).to(device)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()  # 二元交叉熵损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# 训练模型\n",
    "print("开始训练模型...")\n",
    "model = train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    criterion=criterion,\n",
    "    num_epochs=10,  # 为了演示，使用较少的epoch\n",
    "    patience=3\n",
    ")" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 放大显示分割结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化分割结果（支持放大显示）\n",
    "def visualize_predictions_zoom(model, val_loader, num_samples=5, figsize=(16, 12)):\n",
    "    \n",
    "    # 创建保存结果的文件夹\n",
    "    OUTPUT_PATH = os.path.join(os.path.dirname(os.path.abspath('.')), "segmentation_output")\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    \n",
    "    model.eval()\n",
    "    samples_shown = 0\n",
    "    \n",
    "    # 创建大图，用于放大显示所有结果\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            \n",
    "            # 前向传播获取预测结果\n",
    "            outputs = model(images)\n",
    "            preds = (outputs > 0.5).float()\n",
    "            \n",
    "            # 显示结果\n",
    "            for i in range(images.size(0)):\n",
    "                if samples_shown >= num_samples:\n",
    "                    break\n",
    "                \n",
    "                # 反标准化图像以正确显示\n",
    "                image = images[i].cpu().permute(1, 2, 0).numpy()\n",
    "                mean = np.array([0.485, 0.456, 0.406])\n",
    "                std = np.array([0.229, 0.224, 0.225])\n",
    "                image = std * image + mean\n",
    "                image = np.clip(image, 0, 1)\n",
    "                \n",
    "                mask = masks[i].cpu().squeeze().numpy()\n",
    "                pred = preds[i].cpu().squeeze().numpy()\n",
    "                \n",
    "                # 绘制原图\n",
    "                plt.subplot(num_samples, 3, samples_shown * 3 + 1)\n",
    "                plt.imshow(image)\n",
    "                plt.title('原图', fontsize=14)\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # 绘制真实掩码\n",
    "                plt.subplot(num_samples, 3, samples_shown * 3 + 2)\n",
    "                plt.imshow(mask, cmap='gray')\n",
    "                plt.title('真实掩码', fontsize=14)\n",
    "                plt.axis('off')\n",
    "                \n",
    "                # 绘制预测掩码\n",
    "                plt.subplot(num_samples, 3, samples_shown * 3 + 3)\n",
    "                plt.imshow(pred, cmap='gray')\n",
    "                plt.title('预测掩码', fontsize=14)\n",
    "                plt.axis('off')\n",
    "                \n",
    "                samples_shown += 1\n",
    "            \n",
    "            if samples_shown >= num_samples:\n",
    "                break\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.suptitle('图像分割结果展示', fontsize=16)\n",
    "    \n",
    "    # 保存结果\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, 'segmentation_results_zoom.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "# 单独显示单张图片的放大版本\n",
    "def show_single_image_zoom(model, val_loader, figsize=(12, 8)):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # 获取第一个批次的第一张图片\n",
    "        images, masks = next(iter(val_loader))\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        # 前向传播获取预测结果\n",
    "        outputs = model(images)\n",
    "        preds = (outputs > 0.5).float()\n",
    "        \n",
    "        # 处理第一张图片\n",
    "        image = images[0].cpu().permute(1, 2, 0).numpy()\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "        \n",
    "        mask = masks[0].cpu().squeeze().numpy()\n",
    "        pred = preds[0].cpu().squeeze().numpy()\n",
    "        \n",
    "        # 创建大图，用于放大显示单张图片的结果\n",
    "        plt.figure(figsize=figsize)\n",
    "        \n",
    "        # 绘制原图\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.title('原图', fontsize=16)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 绘制真实掩码\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask, cmap='gray')\n",
    "        plt.title('真实掩码', fontsize=16)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # 绘制预测掩码\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(pred, cmap='gray')\n",
    "        plt.title('预测掩码', fontsize=16)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plt.suptitle('单张图片分割结果放大展示', fontsize=18)\n",
    "        plt.show()" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 展示分割结果（放大版本）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载最佳模型权重\n",
    "best_model = UNet(in_channels=3, out_channels=1, features=[64, 128, 256, 512]).to(device)\n",
    "try:\n",
    "    best_model.load_state_dict(torch.load(\n",
    "        os.path.join(os.path.dirname(os.path.abspath('.')), \n",
    "        "segmentation_models", "best_unet_model.pth")\n",
    "    ))\n",
    "    print("成功加载最佳模型权重")\n",
    "except:\n",
    "    print("使用当前训练的模型")\n",
    "    best_model = model\n",
    "\n",
    "# 可视化多张分割结果（放大版）\n",
    "print("\n=== 多张图片分割结果放大展示 ===")\n",
    "visualize_predictions_zoom(best_model, val_loader, num_samples=3, figsize=(18, 16))\n",
    "\n",
    "# 单独放大显示单张图片的分割结果\n",
    "print("\n=== 单张图片分割结果放大展示 ===")\n",
    "show_single_image_zoom(best_model, val_loader, figsize=(15, 8))" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 使用自定义图片进行分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用自定义图片进行分割\n",
    "def segment_custom_image(image_path, model, img_size=(256, 256), figsize=(12, 6)):\n",
    "    # 加载和预处理图片\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    original_size = image.size\n",
    "    \n",
    "    # 定义预处理变换\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(img_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # 预处理图片并添加批次维度\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    # 进行分割预测\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        pred_mask = (output > 0.5).float().squeeze().cpu().numpy()\n",
    "    \n",
    "    # 反预处理原图用于显示\n",
    "    image_tensor = input_tensor.squeeze().cpu()\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    image_np = (image_tensor * std + mean).permute(1, 2, 0).numpy()\n",
    "    image_np = np.clip(image_np, 0, 1)\n",
    "    \n",
    "    # 创建可视化结果\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    # 显示原图\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(image_np)\n",
    "    plt.title('原图', fontsize=16)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # 显示分割结果\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(pred_mask, cmap='gray')\n",
    "    plt.title('分割结果', fontsize=16)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return pred_mask\n",
    "\n",
    "# 示例：如何使用自定义图片进行分割\n",
    "# 如果您有自己的图片，可以取消下面的注释并提供图片路径\n",
    """\n",
    "# 请将下面的路径替换为您自己的图片路径\n",
    "custom_image_path = "/path/to/your/image.jpg"\n",
    "\n",
    "if os.path.exists(custom_image_path):\n",
    "    print(f"\n=== 使用自定义图片 {os.path.basename(custom_image_path)} 进行分割 ===")\n",
    "    pred_mask = segment_custom_image(custom_image_path, best_model, figsize=(15, 8))\n",
    "    print("分割完成！")\n",
    "else:\n",
    "    print(f"未找到图片：{custom_image_path}")\n",
    """" 
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print("图像分割算法演示完成！")\n",
    "print("\n要点总结：")\n",
    "print("1. 我们实现了基于UNet架构的图像分割模型")\n",
    "print("2. 创建了演示数据集并进行了模型训练")\n",
    "print("3. 在Jupyter Notebook中实现了图片的放大显示功能")\n",
    "print("4. 提供了批量和单张图片的分割结果放大展示方法")\n",
    "print("\n如何调整放大效果：")\n",
    "print("- 修改visualize_predictions_zoom函数中的figsize参数来调整整体显示大小")\n",
    "print("- 修改show_single_image_zoom函数中的figsize参数来调整单张图片的显示大小")\n",
    "print("- 增大figsize参数值可以获得更大的显示效果")\n",
    "print("\n如何使用自己的数据：")\n",
    "print("- 将您的图像和对应的掩码放入相应文件夹")\n",
    "print("- 确保图像和掩码文件名对应")\n",
    "print("- 调整SegmentationDataset类中的路径和文件名匹配逻辑")" 
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
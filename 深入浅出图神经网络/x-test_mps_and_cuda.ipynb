{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55a813c4-6308-4624-956c-3e639bdbbf2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:187: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:187: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/s1/1jpfx0m52rj4k7cgqkh7g3q40000gn/T/ipykernel_14100/2609395125.py:187: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  *[int(x) for x in re.findall(\"\\d+\", zh_date_str)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/深入浅出图神经网络\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/深入浅出图神经网络\n",
      "19 15 08\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>火山</th>\n",
       "      <th>泽风</th>\n",
       "      <th>火风</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☲离火</td>\n",
       "      <td>☱兑金</td>\n",
       "      <td>☲离火</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☶艮土</td>\n",
       "      <td>☴巽木</td>\n",
       "      <td>☴巽木</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     火山   泽风   火风\n",
       "上卦  ☲离火  ☱兑金  ☲离火\n",
       "下卦  ☶艮土  ☴巽木  ☴巽木"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08 17 9 申时\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>地天</th>\n",
       "      <th>雷泽</th>\n",
       "      <th>地泽</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>上卦</th>\n",
       "      <td>☷坤土</td>\n",
       "      <td>☳震木</td>\n",
       "      <td>☷坤土</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>下卦</th>\n",
       "      <td>☰乾金</td>\n",
       "      <td>☱兑金</td>\n",
       "      <td>☱兑金</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     地天   雷泽   地泽\n",
       "上卦  ☷坤土  ☳震木  ☷坤土\n",
       "下卦  ☰乾金  ☱兑金  ☱兑金"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('111000', '110100', '110000')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random, os, tqdm, time, json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")\n",
    "\n",
    "def parallelly_run_multiple_similar_python_code(codes, nb_workers = 4):\n",
    "    '''\n",
    "    codes是多条相似的python代码。\n",
    "    这个函数的作用就是将其平行地跑，每一条python代码就对应一个线程。或许可以后续优化，比如固定线程数为一个特定值。\n",
    "    nb_workers 如果赋值为\n",
    "    '''\n",
    "    assert (isinstance(nb_workers, int)), \"`nb_workers' should be int.\"\n",
    "    df_sqls = pd.DataFrame(\n",
    "        {\n",
    "            \"func\": codes\n",
    "\n",
    "        }\n",
    "    )\n",
    "    display(df_sqls)\n",
    "    from pandarallel import pandarallel\n",
    "    pandarallel.initialize(nb_workers = df_sqls.shape[0] if nb_workers<0 else nb_workers, progress_bar = True)\n",
    "    def run_sql_prlly(row):\n",
    "        try: \n",
    "            cmd = f'{row[\"func\"]}'\n",
    "            print(cmd, \"\\n\")\n",
    "            eval(cmd)\n",
    "            return \"0-success\"\n",
    "        except Exception as e:\n",
    "            return e\n",
    "    df_sqls[\"run_rsts\"] = df_sqls.parallel_apply(lambda row: run_sql_prlly(row), axis = 1)\n",
    "    display(df_sqls)\n",
    "    \n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "    \n",
    "class TimerContext:  \n",
    "    def __enter__(self):  \n",
    "        self.start_time = str(datetime.now())\n",
    "        print(\"start time:\", self.start_time)\n",
    "        return self  \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):  \n",
    "        print(\"start time:\", self.start_time)\n",
    "        print(\"end time\", str(datetime.now()))\n",
    "\n",
    "def three_num_get_gua(a, b, c):\n",
    "    '''梅花易数三数起卦，以取本、互、变。'''\n",
    "    bagua = [\"111\", \"110\", \"101\", \"100\", \"011\", \"010\", \"001\", \"000\"]\n",
    "    guatu = {\n",
    "        \"111\": (\"☰\", \"天\", \"乾金\"), \n",
    "        \"110\": (\"☱\", \"泽\", \"兑金\"),\n",
    "        \"101\": (\"☲\", \"火\", \"离火\"),\n",
    "        \"100\": (\"☳\" , \"雷\", \"震木\"),\n",
    "        \"011\": (\"☴\", \"风\", \"巽木\"),\n",
    "        \"010\": (\"☵\", \"水\", \"坎水\"),\n",
    "        \"001\": (\"☶\", \"山\", \"艮土\"),\n",
    "        \"000\": (\"☷\", \"地\", \"坤土\"),\n",
    "    }\n",
    "    shanggua_idx = 7 if (a % 8 == 0) else (a % 8 - 1)\n",
    "    xiagua_idx = 7 if (b % 8 == 0) else (b % 8 - 1)\n",
    "    bianyao_idx = 5 if (c % 6 == 0) else (c % 6 - 1)\n",
    "    bengua = bagua[xiagua_idx] + bagua[shanggua_idx]\n",
    "    hugua = bengua[1:-1][:3] + bengua[1:-1][1:]\n",
    "    biangua = list(bengua)\n",
    "    biangua[bianyao_idx] = str(1 - int(biangua[bianyao_idx]))\n",
    "    biangua = \"\".join(biangua)\n",
    "    df = pd.DataFrame([[\n",
    "        guatu[bengua[3:]][0]+guatu[bengua[3:]][2], guatu[hugua[3:]][0]+guatu[hugua[3:]][2], guatu[biangua[3:]][0]+guatu[biangua[3:]][2], \n",
    "    ],[\n",
    "        guatu[bengua[:3]][0]+guatu[bengua[:3]][2], guatu[hugua[:3]][0]+guatu[hugua[:3]][2], guatu[biangua[:3]][0]+guatu[biangua[:3]][2], \n",
    "    ]], index=[\"上卦\", \"下卦\"], columns = [\n",
    "        guatu[bengua[3:]][1] + guatu[bengua[:3]][1],\n",
    "        guatu[hugua[3:]][1] + guatu[hugua[:3]][1],\n",
    "        guatu[biangua[3:]][1] + guatu[biangua[:3]][1],\n",
    "    ])\n",
    "    display(df)\n",
    "    return bengua, hugua, biangua\n",
    "    \n",
    "def easy_start_gua():\n",
    "    \"\"\"用公历的日、时、分来起卦。\"\"\"\n",
    "    n1, n2, n3 = str(datetime.now())[8:10], str(datetime.now())[11:13], str(datetime.now())[14:16]\n",
    "    print(n1, n2, n3)\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua()\n",
    "\n",
    "import zhdate\n",
    "def easy_start_gua_lunar():\n",
    "    '''用农历的月、日、时辰来起卦。'''\n",
    "    time_now = datetime.now()\n",
    "    zh_date_str = str(zhdate.ZhDate.from_datetime(time_now))\n",
    "    zh_date_str_1 = datetime.strftime(\n",
    "        datetime(\n",
    "            *[int(x) for x in re.findall(\"\\d+\", zh_date_str)]\n",
    "        ),\n",
    "        '%Y-%m-%d'\n",
    "    )\n",
    "    zh_hour = (time_now.hour + 1)//2%12+1\n",
    "    zh_hour_dizhi = \"子、丑、寅、卯、辰、巳、午、未、申、酉、戌、亥\".split(\"、\")[zh_hour-1]\n",
    "    \n",
    "    n1, n2, n3 = zh_date_str_1[5:7], zh_date_str_1[8:10], zh_hour\n",
    "    print(n1, n2, n3, f\"{zh_hour_dizhi}时\")\n",
    "    return three_num_get_gua(int(n1), int(n2), int(n3))\n",
    "easy_start_gua_lunar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeeb6ee6-8e11-4dd1-86a5-efdf9ef50f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/深入浅出图神经网络/originalData/mnist'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_originalData_path(\"mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5a5b172-554c-4854-9670-af74455c0868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time: 2024-09-19 15:08:16.011202\n",
      "Epoch [1/5], Iter [100/600] Loss: 0.1804\n",
      "Epoch [1/5], Iter [200/600] Loss: 0.0697\n",
      "Epoch [1/5], Iter [300/600] Loss: 0.0731\n",
      "Epoch [1/5], Iter [400/600] Loss: 0.0554\n",
      "Epoch [1/5], Iter [500/600] Loss: 0.2074\n",
      "Epoch [1/5], Iter [600/600] Loss: 0.0409\n",
      "Epoch [2/5], Iter [100/600] Loss: 0.0423\n",
      "Epoch [2/5], Iter [200/600] Loss: 0.0516\n",
      "Epoch [2/5], Iter [300/600] Loss: 0.0368\n",
      "Epoch [2/5], Iter [400/600] Loss: 0.0427\n",
      "Epoch [2/5], Iter [500/600] Loss: 0.0960\n",
      "Epoch [2/5], Iter [600/600] Loss: 0.0311\n",
      "Epoch [3/5], Iter [100/600] Loss: 0.0074\n",
      "Epoch [3/5], Iter [200/600] Loss: 0.0171\n",
      "Epoch [3/5], Iter [300/600] Loss: 0.0041\n",
      "Epoch [3/5], Iter [400/600] Loss: 0.0106\n",
      "Epoch [3/5], Iter [500/600] Loss: 0.0441\n",
      "Epoch [3/5], Iter [600/600] Loss: 0.0019\n",
      "Epoch [4/5], Iter [100/600] Loss: 0.0115\n",
      "Epoch [4/5], Iter [200/600] Loss: 0.0479\n",
      "Epoch [4/5], Iter [300/600] Loss: 0.0643\n",
      "Epoch [4/5], Iter [400/600] Loss: 0.0110\n",
      "Epoch [4/5], Iter [500/600] Loss: 0.0603\n",
      "Epoch [4/5], Iter [600/600] Loss: 0.0131\n",
      "Epoch [5/5], Iter [100/600] Loss: 0.0109\n",
      "Epoch [5/5], Iter [200/600] Loss: 0.0020\n",
      "Epoch [5/5], Iter [300/600] Loss: 0.0150\n",
      "Epoch [5/5], Iter [400/600] Loss: 0.0157\n",
      "Epoch [5/5], Iter [500/600] Loss: 0.0162\n",
      "Epoch [5/5], Iter [600/600] Loss: 0.0264\n",
      "start time: 2024-09-19 15:08:16.011202\n",
      "end time 2024-09-19 15:10:00.295385\n"
     ]
    }
   ],
   "source": [
    "## https://www.cnblogs.com/jimchen1218/p/13660800.html\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as normal_datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    " \n",
    "num_epochs = 5\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    " \n",
    " \n",
    "# 将数据处理成Variable, 如果有GPU, 可以转成cuda形式\n",
    "def get_variable(x):\n",
    "    x = Variable(x)\n",
    "    return x.cuda() if torch.cuda.is_available() else x\n",
    " \n",
    " \n",
    "# 从torchvision.datasets中加载一些常用数据集\n",
    "train_dataset = normal_datasets.MNIST(\n",
    "    root=create_originalData_path(\"mnist\"),  # 数据集保存路径\n",
    "    train=True,  # 是否作为训练集\n",
    "    transform=transforms.ToTensor(),  # 数据如何处理, 可以自己自定义\n",
    "    download=True)  # 路径下没有的话, 可以下载\n",
    " \n",
    "# 见数据加载器和batch\n",
    "test_dataset = normal_datasets.MNIST(root=create_originalData_path(\"mnist\"),\n",
    "                                     train=False,\n",
    "                                     transform=transforms.ToTensor())\n",
    " \n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    " \n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    " \n",
    " \n",
    "# 两层卷积\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 使用序列工具快速构建\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))\n",
    "        self.fc = nn.Linear(7 * 7 * 32, 10)\n",
    " \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        out = out.view(out.size(0), -1)  # reshape\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    " \n",
    " \n",
    "cnn = CNN()\n",
    "if torch.cuda.is_available():\n",
    "    cnn = cnn.cuda()\n",
    " \n",
    "# 选择损失函数和优化方法\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=learning_rate)\n",
    "\n",
    "with TimerContext():\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(train_loader):\n",
    "            images = get_variable(images)\n",
    "            labels = get_variable(labels)\n",
    "     \n",
    "            outputs = cnn(images)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "     \n",
    "            if (i + 1) % 100 == 0:\n",
    "                print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n",
    "                      % (epoch + 1, num_epochs, i + 1, len(train_dataset) // batch_size, loss.item()))\n",
    " \n",
    " \n",
    "# Save the Trained Model\n",
    "torch.save(\n",
    "    cnn.state_dict(), \n",
    "    create_trained_models_path('cnn.pkl')\n",
    ")\n",
    "## 我们记录跑了第三次跑的时间吧。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e91655-0374-4d85-ba05-98a7c21256e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6b30350-d7f4-46b1-b1ae-0edaecb93367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67dfdbd-f9b0-4a3c-a430-40404a9e8009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "class TimerContext:  \n",
    "    def __enter__(self):  \n",
    "        self.start_time = str(datetime.now())\n",
    "        print(\"start time:\", self.start_time)\n",
    "        return self  \n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):  \n",
    "        print(\"start time:\", self.start_time)\n",
    "        print(\"end time\", str(datetime.now()))\n",
    "\n",
    "def read_feaList_from_file(fpath, do_lowering = True):\n",
    "    with open(fpath, \"r\") as f:\n",
    "        if do_lowering:\n",
    "            feas = [i.strip().lower() for i in f.readlines()] #  if i.strip() != \"\"\n",
    "        else:\n",
    "            feas = [i.strip() for i in f.readlines()]\n",
    "    print(len(feas), fpath)\n",
    "    return feas\n",
    "\n",
    "def save_feaList_to_file(feas, fpath, mode = \"w\"):\n",
    "    if len(feas) == 0:\n",
    "        print(f\"Finished writing file: {fpath}. Wrote nothing.\")\n",
    "        return\n",
    "    dir_path = os.path.split(fpath)[0]\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    with open(fpath, mode) as f:\n",
    "        f.write(\"\\n\".join(feas) + \"\\n\")\n",
    "    print(f\"Finished writing file: {fpath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458aad6-3be6-4ae8-a6da-fa405fc9ffaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4c25c442-4203-4a7f-95d0-f1a28aae0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87960c4b-7d10-46a6-b0a3-408727478b95",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec965894-3b15-450e-a55d-4a8679769ef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93824dd-2555-4785-b473-ca5a26ed3749",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 尝试初始化一下原始的文本生成模型.\n",
    "## 这个模型是一个生成模型哦。\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    create_trained_models_path(\"Qwen1.5-0.5B-Chat\")\n",
    ").to(\"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0894dbd-1a03-4279-9fba-652effaeee0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(create_trained_models_path(\"Qwen1.5-0.5B-Chat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53deba80-675e-4a2f-8aa2-46d367cba309",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 准备数据吧。\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个有文化的文明人\"},\n",
    "    {\"role\": \"user\", \"content\": \"饭店服务员的态度太差，使用委婉积极的态度投诉\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e1d1efa5-7a80-4de5-9f15-ca06889232ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574e0e08-cf07-4a73-b29d-0a885bdd5bd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,  56568, 101909,  18830, 107705, 100704,  17340,\n",
       "         151645,    198, 151644,    872,    198, 107514, 112822, 105421,  99222,\n",
       "          99572,   3837,  37029,  99199, 106783,  99666, 105421, 104943, 151645,\n",
       "            198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\")\n",
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a989b3c9-4eaf-4bcb-994f-dda2d26cd9de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs.input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6ec3252-2e88-4080-8730-0ba819eedb63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31, 1024])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\n",
    "    model_inputs.input_ids, model_inputs.attention_mask, \n",
    "    output_hidden_states=True ## 这个是个什么玩意儿呢？就是hiddenstate。这个东西经过一个 hiddenstate -> token数 的映射之后，变成了logits。\n",
    ").hidden_states[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b847e30c-4f6a-4584-ad75-28756520e5ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d0d5295-3936-4cd7-8477-eb718a0fdc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 39349,  39349, 151644, 151645, 151645, 151645, 151645, 151645, 151645,\n",
       "            198, 151644,  20412, 151645, 151644, 151645, 151645, 151645, 151645,\n",
       "         151645, 151645, 151645, 106783, 151645, 151645, 151645, 151645,    198,\n",
       "         151644, 102056, 109723, 109723]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(\n",
    "    model(model_inputs.input_ids, model_inputs.attention_mask).logits, \n",
    "    dim=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb1ee8be-f485-45a1-bec4-edf5a7326ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.mybatis',\n",
       " '.mybatis',\n",
       " '<|im_start|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '\\n',\n",
       " '<|im_start|>',\n",
       " '是',\n",
       " '<|im_end|>',\n",
       " '<|im_start|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '婉',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '\\n',\n",
       " '<|im_start|>',\n",
       " '如果你',\n",
       " '尊敬',\n",
       " '尊敬']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([ 39349,  39349, 151644, 151645, 151645, 151645, 151645, 151645, 151645,\n",
    "            198, 151644,  20412, 151645, 151644, 151645, 151645, 151645, 151645,\n",
    "         151645, 151645, 151645, 106783, 151645, 151645, 151645, 151645,    198,\n",
    "         151644, 102056, 109723, 109723])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0485a403-7514-4d93-aa59-56ec2b8fe659",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f6081455-0621-4c26-95ac-b55cbf2a2018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,  56568, 101909,  18830, 107705, 100704,  17340,\n",
       "         151645,    198, 151644,    872,    198, 107514, 112822, 105421,  99222,\n",
       "          99572,   3837,  37029,  99199, 106783,  99666, 105421, 104943, 151645,\n",
       "            198, 151644,  77091,    198,  99491, 115546, 104188,  87026,  32664,\n",
       "         112822,  47874, 102316,   9370, 106974,   1773,  43288,  87267, 104404,\n",
       "         101214, 106076,  33108, 106076,  80443]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(\n",
    "    model_inputs.input_ids, \n",
    "    max_length = 50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea460141-42aa-4576-a0e2-d2d51d227811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>',\n",
       " 'system',\n",
       " '\\n',\n",
       " '你',\n",
       " '是一个',\n",
       " '有',\n",
       " '文化的',\n",
       " '文明',\n",
       " '人',\n",
       " '<|im_end|>',\n",
       " '\\n',\n",
       " '<|im_start|>',\n",
       " 'user',\n",
       " '\\n',\n",
       " '饭店',\n",
       " '服务员',\n",
       " '的态度',\n",
       " '太',\n",
       " '差',\n",
       " '，',\n",
       " '使用',\n",
       " '委',\n",
       " '婉',\n",
       " '积极',\n",
       " '的态度',\n",
       " '投诉',\n",
       " '<|im_end|>',\n",
       " '\\n',\n",
       " '<|im_start|>',\n",
       " 'assistant',\n",
       " '\\n',\n",
       " '非常',\n",
       " '抱歉',\n",
       " '听到',\n",
       " '您',\n",
       " '对',\n",
       " '服务员',\n",
       " '服务',\n",
       " '态度',\n",
       " '的',\n",
       " '不满',\n",
       " '。',\n",
       " '这',\n",
       " '可能',\n",
       " '是因为',\n",
       " '您的',\n",
       " '期望',\n",
       " '和',\n",
       " '期望',\n",
       " '没有']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode([151644,   8948,    198,  56568, 101909,  18830, 107705, 100704,  17340,\n",
    "         151645,    198, 151644,    872,    198, 107514, 112822, 105421,  99222,\n",
    "          99572,   3837,  37029,  99199, 106783,  99666, 105421, 104943, 151645,\n",
    "            198, 151644,  77091,    198,  99491, 115546, 104188,  87026,  32664,\n",
    "         112822,  47874, 102316,   9370, 106974,   1773,  43288,  87267, 104404,\n",
    "         101214, 106076,  33108, 106076,  80443])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57f18968-2988-4d02-980e-460f4104b1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([151644,   8948,    198,  56568, 101909,  18830, 107705, 100704,  17340,\n",
    "         151645,    198, 151644,    872,    198, 107514, 112822, 105421,  99222,\n",
    "          99572,   3837,  37029,  99199, 106783,  99666, 105421, 104943, 151645,\n",
    "            198, 151644,  77091,    198,  99491, 115546, 104188,  87026,  32664,\n",
    "         112822,  47874, 102316,   9370, 106974,   1773,  43288,  87267, 104404,\n",
    "         101214, 106076,  33108, 106076,  80443])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a17b2b-1883-4a5a-9919-eef23fd5b890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e95505-e5ae-41f4-abb1-4c10f0a1810f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664db93f-fdb5-4d05-884b-42a1a4921793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50b18b7-6b09-43eb-a451-32fe325db0d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8fb5a6-b898-4410-8662-8626c9984397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1009dd-1782-48ce-a10b-bf41a6cba2fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b775abeb-bc53-4202-a9cd-a1e17b4f24ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb176ca-e09d-4ad5-846a-f9c3bd9aa844",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e3bddecf-454c-406a-9014-ba28aa661deb",
   "metadata": {},
   "source": [
    "## Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "885df9cf-1754-45fc-b832-8ce4636cf667",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7410f44-6a57-4d5a-ae34-7cc583810413",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=2, ## 把秩降到这个数。\n",
    "    lora_alpha=8, ## 这个是一个扩张系数。\n",
    "    target_modules=['k_proj',  'v_proj'],\n",
    "    lora_dropout=0,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e08ace64-1862-417a-b56a-0880c56c0244",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = PeftModel(model, lora_config)\n",
    "v_head = torch.nn.Linear(1024, 1, bias=False).to(\"cpu\")\n",
    "for name, module in lora_model.named_modules():\n",
    "    if 'lora_' in name:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41f1553d-24f8-4ed7-aacf-0fe6fda9d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = lora_model.generate(\n",
    "    model_inputs.input_ids, \n",
    "    max_new_tokens=512, \n",
    "    top_p=1.0,\n",
    "    num_beams=1,\n",
    "    do_sample=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff32f77d-0de7-408c-b6f6-9aa3ae092a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2acad209-0ddc-45e7-9db0-6bade134b404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2ForCausalLM(\n",
       "  (model): Qwen2Model(\n",
       "    (embed_tokens): Embedding(151936, 1024)\n",
       "    (layers): ModuleList(\n",
       "      (0-23): 24 x Qwen2DecoderLayer(\n",
       "        (self_attn): Qwen2SdpaAttention(\n",
       "          (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (o_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
       "          (rotary_emb): Qwen2RotaryEmbedding()\n",
       "        )\n",
       "        (mlp): Qwen2MLP(\n",
       "          (gate_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (up_proj): Linear(in_features=1024, out_features=2816, bias=False)\n",
       "          (down_proj): Linear(in_features=2816, out_features=1024, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): Qwen2RMSNorm()\n",
       "        (post_attention_layernorm): Qwen2RMSNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): Qwen2RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=151936, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoModelForCausalLM.from_pretrained(\n",
    "    create_trained_models_path(\"Qwen1.5-0.5B-Chat\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466668f-68c5-46c9-b866-18c60f902992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1178f19a-58a6-401e-8f13-83db38874659",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Qwen2ForCausalLM' object has no attribute 'super'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/peft/peft_model.py:619\u001b[0m, in \u001b[0;36mPeftModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PeftModel' object has no attribute 'super'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/peft/tuners/lora/model.py:330\u001b[0m, in \u001b[0;36mLoraModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getattr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LoraModel' object has no attribute 'super'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlora_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuper\u001b[49m()\u001b[38;5;66;03m#.base_model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/peft/peft_model.py:621\u001b[0m, in \u001b[0;36mPeftModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name)  \u001b[38;5;66;03m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    620\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/peft/tuners/lora/model.py:332\u001b[0m, in \u001b[0;36mLoraModel.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattr__\u001b[39m(name)  \u001b[38;5;66;03m# defer to nn.Module's logic\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml12/lib/python3.12/site-packages/torch/nn/modules/module.py:1688\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1687\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1688\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Qwen2ForCausalLM' object has no attribute 'super'"
     ]
    }
   ],
   "source": [
    "lora_model.super()#.base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bade4cf-816c-4451-bba3-7a11aed81634",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b042b2-54f9-4d76-a331-4634528577fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ba5789-db3b-45a6-a6b5-7e860b551115",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

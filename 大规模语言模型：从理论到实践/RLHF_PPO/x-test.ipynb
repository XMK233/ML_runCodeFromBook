{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8d49c2-a8ee-40b3-9c56-7fba0925e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205dd34-66bd-4823-bfba-40e0bb971774",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# (之前的草稿)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430c7872-c344-4dd4-9d20-fc4bdc19841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载acm的tokenizer，\n",
    "## 加载一下数据试试看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1471894-af16-4718-83a6-80d0ab00d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(create_trained_models_path(\"Qwen1.5-0.5B-Chat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77b9689-ee3d-433b-8322-a32b5b2db2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='/Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO/trained_models/Qwen1.5-0.5B-Chat', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5817fc71-7d6c-47c5-9c87-59961f135c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载一下数据：\n",
    "with open(\n",
    "    \"/Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO/data/train_data.json\", \n",
    "    'r', \n",
    "    encoding=\"utf-8\"\n",
    ") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d98d2e-1e23-4f6d-aa5e-84293e187afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': '饭店服务员的态度太差，使用委婉积极的态度投诉', 'system_content': '你是一个有文化的文明人'},\n",
       " {'query': '领导故意刁难你，你想骂他娘的，使用文明语言骂他娘的', 'system_content': '你是一个有文化的文明人'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "## 数据大概长这样。有一个query，有一个system_content。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09ad7f-b98b-418e-9ba6-84fcc67e05b7",
   "metadata": {},
   "source": [
    "# 尝试一下呗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d6ca0f-3c8a-48a6-b361-fb94d633c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a4d000-e624-4e70-8cdc-d4a5810c83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a63b18a-9fd0-4cd0-b042-531bd2f9b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992954af-a75c-403f-8e19-b3c9d07ad28a",
   "metadata": {},
   "source": [
    "# 初始化一个演员·评论员模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc604ee-7acd-453f-befd-2ef2497d254d",
   "metadata": {},
   "source": [
    "## 演员·评论员"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aef0609b-1950-434d-ab79-0b9565d58d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 尝试初始化一下原始的文本生成模型.\n",
    "## 这个模型是一个生成模型哦。\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    create_trained_models_path(\"Qwen1.5-0.5B-Chat\")\n",
    ").to(\"cpu\").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "758f9a18-cc14-468b-ab76-3e28d0ca76d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(create_trained_models_path(\"Qwen1.5-0.5B-Chat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e3df026e-900b-4ae3-897c-fddf040ec9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 准备数据吧。\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是一个有文化的文明人\"},\n",
    "    {\"role\": \"user\", \"content\": \"饭店服务员的态度太差，使用委婉积极的态度投诉\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "77c96682-41bc-425e-8add-b2970880c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cb31115-1a4d-4ff7-8471-ae577ebac10f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|im_start|>system\\n你是一个有文化的文明人<|im_end|>\\n<|im_start|>user\\n饭店服务员的态度太差，使用委婉积极的态度投诉<|im_end|>\\n<|im_start|>assistant\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9544dcc6-99b3-4666-b929-6a7d232f976c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m     \n",
       "\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_pair\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtext_pair_target\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpadding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPaddingStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtruncation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTruncationStrategy\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmax_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mstride\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpad_to_multiple_of\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_token_type_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_attention_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_overflowing_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_special_tokens_mask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_offsets_mapping\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mreturn_length\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization_utils_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchEncoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           Qwen2TokenizerFast\n",
       "\u001b[0;31mString form:\u001b[0m   \n",
       "Qwen2TokenizerFast(name_or_path='/Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到 <...> n(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "           }\n",
       "\u001b[0;31mLength:\u001b[0m         151646\n",
       "\u001b[0;31mFile:\u001b[0m           /opt/anaconda3/envs/ml12/lib/python3.12/site-packages/transformers/models/qwen2/tokenization_qwen2_fast.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Construct a \"fast\" Qwen2 tokenizer (backed by HuggingFace's *tokenizers* library). Based on byte-level\n",
       "Byte-Pair-Encoding.\n",
       "\n",
       "Same with GPT2Tokenizer, this tokenizer has been trained to treat spaces like parts of the tokens so a word will\n",
       "be encoded differently whether it is at the beginning of the sentence (without space) or not:\n",
       "\n",
       "```python\n",
       ">>> from transformers import Qwen2TokenizerFast\n",
       "\n",
       ">>> tokenizer = Qwen2TokenizerFast.from_pretrained(\"Qwen/Qwen-tokenizer\")\n",
       ">>> tokenizer(\"Hello world\")[\"input_ids\"]\n",
       "[9707, 1879]\n",
       "\n",
       ">>> tokenizer(\" Hello world\")[\"input_ids\"]\n",
       "[21927, 1879]\n",
       "```\n",
       "This is expected.\n",
       "\n",
       "This tokenizer inherits from [`PreTrainedTokenizerFast`] which contains most of the main methods. Users should\n",
       "refer to this superclass for more information regarding those methods.\n",
       "\n",
       "Args:\n",
       "    vocab_file (`str`, *optional*):\n",
       "        Path to the vocabulary file.\n",
       "    merges_file (`str`, *optional*):\n",
       "        Path to the merges file.\n",
       "    tokenizer_file (`str`, *optional*):\n",
       "        Path to [tokenizers](https://github.com/huggingface/tokenizers) file (generally has a .json extension) that\n",
       "        contains everything needed to load the tokenizer.\n",
       "    unk_token (`str`, *optional*, defaults to `\"<|endoftext|>\"`):\n",
       "        The unknown token. A token that is not in the vocabulary cannot be converted to an ID and is set to be this\n",
       "        token instead. Not applicable to this tokenizer.\n",
       "    bos_token (`str`, *optional*):\n",
       "        The beginning of sequence token. Not applicable for this tokenizer.\n",
       "    eos_token (`str`, *optional*, defaults to `\"<|endoftext|>\"`):\n",
       "        The end of sequence token.\n",
       "    pad_token (`str`, *optional*, defaults to `\"<|endoftext|>\"`):\n",
       "        The token used for padding, for example when batching sequences of different lengths.\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "Main method to tokenize and prepare for the model one or several sequence(s) or one or several pair(s) of\n",
       "sequences.\n",
       "\n",
       "Args:\n",
       "    text (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings\n",
       "        (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set\n",
       "        `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "    text_pair (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded. Each sequence can be a string or a list of strings\n",
       "        (pretokenized string). If the sequences are provided as list of strings (pretokenized), you must set\n",
       "        `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "    text_target (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded as target texts. Each sequence can be a string or a\n",
       "        list of strings (pretokenized string). If the sequences are provided as list of strings (pretokenized),\n",
       "        you must set `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "    text_pair_target (`str`, `List[str]`, `List[List[str]]`, *optional*):\n",
       "        The sequence or batch of sequences to be encoded as target texts. Each sequence can be a string or a\n",
       "        list of strings (pretokenized string). If the sequences are provided as list of strings (pretokenized),\n",
       "        you must set `is_split_into_words=True` (to lift the ambiguity with a batch of sequences).\n",
       "\n",
       "    add_special_tokens (`bool`, *optional*, defaults to `True`):\n",
       "        Whether or not to add special tokens when encoding the sequences. This will use the underlying\n",
       "        `PretrainedTokenizerBase.build_inputs_with_special_tokens` function, which defines which tokens are\n",
       "        automatically added to the input ids. This is usefull if you want to add `bos` or `eos` tokens\n",
       "        automatically.\n",
       "    padding (`bool`, `str` or [`~utils.PaddingStrategy`], *optional*, defaults to `False`):\n",
       "        Activates and controls padding. Accepts the following values:\n",
       "\n",
       "        - `True` or `'longest'`: Pad to the longest sequence in the batch (or no padding if only a single\n",
       "          sequence if provided).\n",
       "        - `'max_length'`: Pad to a maximum length specified with the argument `max_length` or to the maximum\n",
       "          acceptable input length for the model if that argument is not provided.\n",
       "        - `False` or `'do_not_pad'` (default): No padding (i.e., can output a batch with sequences of different\n",
       "          lengths).\n",
       "    truncation (`bool`, `str` or [`~tokenization_utils_base.TruncationStrategy`], *optional*, defaults to `False`):\n",
       "        Activates and controls truncation. Accepts the following values:\n",
       "\n",
       "        - `True` or `'longest_first'`: Truncate to a maximum length specified with the argument `max_length` or\n",
       "          to the maximum acceptable input length for the model if that argument is not provided. This will\n",
       "          truncate token by token, removing a token from the longest sequence in the pair if a pair of\n",
       "          sequences (or a batch of pairs) is provided.\n",
       "        - `'only_first'`: Truncate to a maximum length specified with the argument `max_length` or to the\n",
       "          maximum acceptable input length for the model if that argument is not provided. This will only\n",
       "          truncate the first sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
       "        - `'only_second'`: Truncate to a maximum length specified with the argument `max_length` or to the\n",
       "          maximum acceptable input length for the model if that argument is not provided. This will only\n",
       "          truncate the second sequence of a pair if a pair of sequences (or a batch of pairs) is provided.\n",
       "        - `False` or `'do_not_truncate'` (default): No truncation (i.e., can output batch with sequence lengths\n",
       "          greater than the model maximum admissible input size).\n",
       "    max_length (`int`, *optional*):\n",
       "        Controls the maximum length to use by one of the truncation/padding parameters.\n",
       "\n",
       "        If left unset or set to `None`, this will use the predefined model maximum length if a maximum length\n",
       "        is required by one of the truncation/padding parameters. If the model has no specific maximum input\n",
       "        length (like XLNet) truncation/padding to a maximum length will be deactivated.\n",
       "    stride (`int`, *optional*, defaults to 0):\n",
       "        If set to a number along with `max_length`, the overflowing tokens returned when\n",
       "        `return_overflowing_tokens=True` will contain some tokens from the end of the truncated sequence\n",
       "        returned to provide some overlap between truncated and overflowing sequences. The value of this\n",
       "        argument defines the number of overlapping tokens.\n",
       "    is_split_into_words (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not the input is already pre-tokenized (e.g., split into words). If set to `True`, the\n",
       "        tokenizer assumes the input is already split into words (for instance, by splitting it on whitespace)\n",
       "        which it will tokenize. This is useful for NER or token classification.\n",
       "    pad_to_multiple_of (`int`, *optional*):\n",
       "        If set will pad the sequence to a multiple of the provided value. Requires `padding` to be activated.\n",
       "        This is especially useful to enable the use of Tensor Cores on NVIDIA hardware with compute capability\n",
       "        `>= 7.5` (Volta).\n",
       "    return_tensors (`str` or [`~utils.TensorType`], *optional*):\n",
       "        If set, will return tensors instead of list of python integers. Acceptable values are:\n",
       "\n",
       "        - `'tf'`: Return TensorFlow `tf.constant` objects.\n",
       "        - `'pt'`: Return PyTorch `torch.Tensor` objects.\n",
       "        - `'np'`: Return Numpy `np.ndarray` objects.\n",
       "\n",
       "    return_token_type_ids (`bool`, *optional*):\n",
       "        Whether to return token type IDs. If left to the default, will return the token type IDs according to\n",
       "        the specific tokenizer's default, defined by the `return_outputs` attribute.\n",
       "\n",
       "        [What are token type IDs?](../glossary#token-type-ids)\n",
       "    return_attention_mask (`bool`, *optional*):\n",
       "        Whether to return the attention mask. If left to the default, will return the attention mask according\n",
       "        to the specific tokenizer's default, defined by the `return_outputs` attribute.\n",
       "\n",
       "        [What are attention masks?](../glossary#attention-mask)\n",
       "    return_overflowing_tokens (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return overflowing token sequences. If a pair of sequences of input ids (or a batch\n",
       "        of pairs) is provided with `truncation_strategy = longest_first` or `True`, an error is raised instead\n",
       "        of returning overflowing tokens.\n",
       "    return_special_tokens_mask (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return special tokens mask information.\n",
       "    return_offsets_mapping (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return `(char_start, char_end)` for each token.\n",
       "\n",
       "        This is only available on fast tokenizers inheriting from [`PreTrainedTokenizerFast`], if using\n",
       "        Python's tokenizer, this method will raise `NotImplementedError`.\n",
       "    return_length  (`bool`, *optional*, defaults to `False`):\n",
       "        Whether or not to return the lengths of the encoded inputs.\n",
       "    verbose (`bool`, *optional*, defaults to `True`):\n",
       "        Whether or not to print more information and warnings.\n",
       "    **kwargs: passed to the `self.tokenize()` method\n",
       "\n",
       "Return:\n",
       "    [`BatchEncoding`]: A [`BatchEncoding`] with the following fields:\n",
       "\n",
       "    - **input_ids** -- List of token ids to be fed to a model.\n",
       "\n",
       "      [What are input IDs?](../glossary#input-ids)\n",
       "\n",
       "    - **token_type_ids** -- List of token type ids to be fed to a model (when `return_token_type_ids=True` or\n",
       "      if *\"token_type_ids\"* is in `self.model_input_names`).\n",
       "\n",
       "      [What are token type IDs?](../glossary#token-type-ids)\n",
       "\n",
       "    - **attention_mask** -- List of indices specifying which tokens should be attended to by the model (when\n",
       "      `return_attention_mask=True` or if *\"attention_mask\"* is in `self.model_input_names`).\n",
       "\n",
       "      [What are attention masks?](../glossary#attention-mask)\n",
       "\n",
       "    - **overflowing_tokens** -- List of overflowing tokens sequences (when a `max_length` is specified and\n",
       "      `return_overflowing_tokens=True`).\n",
       "    - **num_truncated_tokens** -- Number of tokens truncated (when a `max_length` is specified and\n",
       "      `return_overflowing_tokens=True`).\n",
       "    - **special_tokens_mask** -- List of 0s and 1s, with 1 specifying added special tokens and 0 specifying\n",
       "      regular sequence tokens (when `add_special_tokens=True` and `return_special_tokens_mask=True`).\n",
       "    - **length** -- The length of the inputs (when `return_length=True`)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c089635e-76f3-4a56-943e-5f3d09760d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "861c4bdf-a05f-4487-8710-686821d78c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    198,  56568, 101909,  18830, 107705, 100704,  17340,\n",
       "         151645,    198, 151644,    872,    198, 107514, 112822, 105421,  99222,\n",
       "          99572,   3837,  37029,  99199, 106783,  99666, 105421, 104943, 151645,\n",
       "            198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d7c6cbf4-1f64-4da7-857d-a9f88004ce89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[151644,\n",
       "  8948,\n",
       "  198,\n",
       "  56568,\n",
       "  101909,\n",
       "  18830,\n",
       "  107705,\n",
       "  100704,\n",
       "  17340,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  872,\n",
       "  198,\n",
       "  107514,\n",
       "  112822,\n",
       "  105421,\n",
       "  99222,\n",
       "  99572,\n",
       "  3837,\n",
       "  37029,\n",
       "  99199,\n",
       "  106783,\n",
       "  99666,\n",
       "  105421,\n",
       "  104943,\n",
       "  151645,\n",
       "  198,\n",
       "  151644,\n",
       "  77091,\n",
       "  198],\n",
       " [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    model_inputs.input_ids.tolist()[0], \n",
    "    model_inputs.attention_mask.tolist()[0]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a766a-d3e1-4a7c-b782-ae6c08a674b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161d1a3-8eb9-45f5-9443-97e3afb99843",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7449b969-1961-4007-ac61-419dbdb6503e",
   "metadata": {},
   "source": [
    "## Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc5d58a9-85b1-45f5-a213-49690bd24de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8947351e-1e19-4b61-bca4-ace5a222ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=2, ## 把秩降到这个数。\n",
    "    lora_alpha=8, ## 这个是一个扩张系数。\n",
    "    target_modules=['k_proj',  'v_proj'],\n",
    "    lora_dropout=0,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2169070-311b-4474-a3e2-09899d26db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = PeftModel(model, lora_config)\n",
    "v_head = torch.nn.Linear(1024, 1, bias=False).to(\"cpu\")\n",
    "for name, module in lora_model.named_modules():\n",
    "    if 'lora_' in name:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "88aea91a-7c7c-4c73-98f8-6d8ecb343518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def lora_forward(input_ids, attention_mask, tools):\n",
    "#     res = lora_model.forward(input_ids, attention_mask, output_hidden_states=True)\n",
    "#     values = v_head(res.hidden_states[0]).squeeze(-1)[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ad7bc3f-f7e3-44ab-aa7e-dcc8be6f863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\n你是一个有文化的文明人<|im_end|>\\n<|im_start|>user\\n饭店服务员的态度太差，使用委婉积极的态度投诉<|im_end|>\\n<|im_start|>assistant\\n']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(model_inputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5d99c835-04c7-4e7b-b59f-dfb78b751ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_ids = lora_model.generate(model_inputs.input_ids, max_new_tokens=512, top_p=1.0,\n",
    "                                            num_beams=1,\n",
    "                                            do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83c2a305-889e-47b5-918c-7828f5e15159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e9beff56-f8d8-44cd-a37c-8c856c8cd969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system\\n你是一个有文化的文明人\\nuser\\n饭店服务员的态度太差，使用委婉积极的态度投诉\\nassistant\\n尊敬的经理：\\n\\n您好！我最近在您的饭店用餐时遇到了一些问题。我想通过这封信向您反映一下。\\n\\n首先，我对餐厅的服务态度感到非常不满。当我点菜时，服务员的态度并不友好，总是显得有些冷漠和不耐烦。他们似乎对我的需求没有足够的关注，甚至有时会对我提出一些不合理的建议或要求。\\n\\n其次，我在用餐过程中也遇到了一些困扰。我发现有些菜品的味道并不符合我的口味，而且有些服务人员的服务态度也不够热情。这些都让我感到很失望。\\n\\n最后，我还注意到有一些环境问题。例如，餐厅的卫生状况不佳，餐具和杯子经常被污染，这让我感到非常不舒服。\\n\\n我希望您能理解并采取措施来改善我们的用餐体验。我相信，只要我们共同努力，我们的服务质量将会得到显著提高。\\n\\n再次感谢您抽出宝贵的时间阅读这封信，并期待您的回复。\\n\\n顺祝商祺，\\n[你的名字]']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True) ## 这个就是把id解码成自然语言字符。\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "91c5ac75-0f6b-46d4-978e-689a456d39d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_id = generated_ids[:, model_inputs.input_ids.shape[1]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72f1a868-ef5c-4409-bc05-0e834b7027c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1e257aad-66aa-447e-a6d0-91a5bd906279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system\\n你是一个有文化的文明人\\nuser\\n饭店服务员的态度太差，使用委婉积极的态度投诉\\nassistant\\n尊敬的经理：\\n\\n您好！我最近在您的饭店用餐时遇到了一些问题。我想通过这封信向您反映一下。\\n\\n首先，我对餐厅的服务态度感到非常不满。当我点菜时，服务员的态度并不友好，总是显得有些冷漠和不耐烦。他们似乎对我的需求没有足够的关注，甚至有时会对我提出一些不合理的建议或要求。\\n\\n其次，我在用餐过程中也遇到了一些困扰。我发现有些菜品的味道并不符合我的口味，而且有些服务人员的服务态度也不够热情。这些都让我感到很失望。\\n\\n最后，我还注意到有一些环境问题。例如，餐厅的卫生状况不佳，餐具和杯子经常被污染，这让我感到非常不舒服。\\n\\n我希望您能理解并采取措施来改善我们的用餐体验。我相信，只要我们共同努力，我们的服务质量将会得到显著提高。\\n\\n再次感谢您抽出宝贵的时间阅读这封信，并期待您的回复。\\n\\n顺祝商祺，\\n[你的名字]']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9cab4fce-465f-4abd-af4e-1e13e3a6b625",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 193])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "48e9c894-df54-48c8-8ac6-ef6a7d7ec73d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system\\n你是一个有文化的文明人\\nuser\\n饭店服务员的态度太差，使用委婉积极的态度投诉\\nassistant\\n尊敬的经理：\\n\\n您好！我最近在您的饭店用餐时遇到了一些问题。我想通过这封信向您反映一下。\\n\\n首先，我对餐厅的服务态度感到非常不满。当我点菜时，服务员的态度并不友好，总是显得有些冷漠和不耐烦。他们似乎对我的需求没有足够的关注，甚至有时会对我提出一些不合理的建议或要求。\\n\\n其次，我在用餐过程中也遇到了一些困扰。我发现有些菜品的味道并不符合我的口味，而且有些服务人员的服务态度也不够热情。这些都让我感到很失望。\\n\\n最后，我还注意到有一些环境问题。例如，餐厅的卫生状况不佳，餐具和杯子经常被污染，这让我感到非常不舒服。\\n\\n我希望您能理解并采取措施来改善我们的用餐体验。我相信，只要我们共同努力，我们的服务质量将会得到显著提高。\\n\\n再次感谢您抽出宝贵的时间阅读这封信，并期待您的回复。\\n\\n顺祝商祺，\\n[你的名字]']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate = response\n",
    "prompt_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2c180e2-31f5-420c-a872-53afbca247fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151644,   8948,    198,  56568, 101909,  18830, 107705, 100704,  17340,\n",
       "         151645,    198, 151644,    872,    198, 107514, 112822, 105421,  99222,\n",
       "          99572,   3837,  37029,  99199, 106783,  99666, 105421, 104943, 151645,\n",
       "            198, 151644,  77091,    198, 109723,   9370, 100249,  48443, 111308,\n",
       "           6313,  35946, 104044,  18493, 101214, 107514, 111554,  13343, 109075,\n",
       "         101883,  86119,   1773, 104100,  67338,  43288,  99690,  21317,  69041,\n",
       "          87026, 101279, 100158,   3407, 101140,   3837, 108531, 104835, 105646,\n",
       "         102316, 104048,  99491, 106974,   1773, 108089,  27442,  99800,  13343,\n",
       "           3837, 112822, 105421, 100684, 106098,   3837, 104014, 104392, 101895,\n",
       "         113808,  33108,  16530, 100796, 100886,   1773,  99650, 101994,  32664,\n",
       "          97611, 100354,  80443, 103170, 100020,   3837, 100636, 104685,  36993,\n",
       "         102788, 101080, 101883,  16530, 105630, 101898,  57191, 101882,   3407,\n",
       "         102460,   3837, 104786, 111554, 101925,  74763, 109075, 101883, 107526,\n",
       "           1773, 111003, 101895, 115915, 107254, 100684, 101137,  97611, 107102,\n",
       "           3837, 101885, 101895,  47874,  99653, 105646, 102316,  99744,  99521,\n",
       "         102379,   1773, 100001,  71268, 104029, 104048,  99165, 106586,   3407,\n",
       "         100161,   3837, 107228, 106394, 101529,  99719,  86119,   1773,  77557,\n",
       "           3837, 104835,   9370, 100200, 104215, 110871,   3837, 116764,  33108,\n",
       "         116120, 101942,  99250, 100791,   3837,  43288, 104029, 104048,  99491,\n",
       "         110237,   3407, 110875,  87026,  26232, 101128,  62926, 103975, 101082,\n",
       "          36407, 104009, 103952, 111554, 101904,   1773, 107451,   3837, 100671,\n",
       "          97639, 112061,   3837, 103952, 111333, 104347, 101051, 104656, 100627,\n",
       "           3407, 103989, 104305,  87026, 113805, 103562, 101975, 101113,  43288,\n",
       "          99690,  21317,  90395, 104177, 101214, 104787,   3407,  99683, 100549,\n",
       "          32022, 115464,  41453,     58, 103929, 101419,     60, 151645]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate_ids = generated_ids\n",
    "prompt_generate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "22e48411-29fe-4390-b654-a93b418b494d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 193])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ids = response_id\n",
    "generate_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fe4233cb-9a91-4bb2-999a-f7eceb880312",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mask = (prompt_generate_ids != tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fa1a5c44-c668-4221-82f7-53f58ed048f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1e7cb4a7-c22a-4454-9ca0-a414cdba660f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 193])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "310e63ff-6c87-4798-94f9-cb39d11cc7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_end|>']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(generate_ids[:, -1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d7e61cb1-2171-405e-b334-a44d81677582",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True, True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ids_mask = (generate_ids[\n",
    "                     :, \n",
    "                     :-1 ## 这里省掉了最后的结尾符。\n",
    "                     ] != tokenizer.pad_token_id)\n",
    "generate_ids_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d114e238-a12b-4a4a-851e-e0101e90a291",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_shape = generate_ids.shape[1] - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8507dedf-a684-4876-9693-418441dd51db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a1ff7910-317e-4bbe-8d89-5de40a0fc8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_ids_mask = generate_ids_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c79ee40-3610-4117-be06-241fb52b63f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f699683-eff8-423b-86e9-5b014caf7427",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de497431-f3d2-4ae7-bc1d-9ed610212cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e601f299-7006-49a4-9a7d-46eeaaf267ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['system\\n你是一个有文化的文明人\\nuser\\n饭店服务员的态度太差，使用委婉积极的态度投诉\\nassistant\\n尊敬的经理：\\n\\n您好！我最近在您的饭店用餐时遇到了一些问题。我想通过这封信向您反映一下。\\n\\n首先，我对餐厅的服务态度感到非常不满。当我点菜时，服务员的态度并不友好，总是显得有些冷漠和不耐烦。他们似乎对我的需求没有足够的关注，甚至有时会对我提出一些不合理的建议或要求。\\n\\n其次，我在用餐过程中也遇到了一些困扰。我发现有些菜品的味道并不符合我的口味，而且有些服务人员的服务态度也不够热情。这些都让我感到很失望。\\n\\n最后，我还注意到有一些环境问题。例如，餐厅的卫生状况不佳，餐具和杯子经常被污染，这让我感到非常不舒服。\\n\\n我希望您能理解并采取措施来改善我们的用餐体验。我相信，只要我们共同努力，我们的服务质量将会得到显著提高。\\n\\n再次感谢您抽出宝贵的时间阅读这封信，并期待您的回复。\\n\\n顺祝商祺，\\n[你的名字]']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7ba50a50-c69b-4b52-8c77-5fe457c8c26a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['尊敬的经理：\\n\\n您好！我最近在您的饭店用餐时遇到了一些问题。我想通过这封信向您反映一下。\\n\\n首先，我对餐厅的服务态度感到非常不满。当我点菜时，服务员的态度并不友好，总是显得有些冷漠和不耐烦。他们似乎对我的需求没有足够的关注，甚至有时会对我提出一些不合理的建议或要求。\\n\\n其次，我在用餐过程中也遇到了一些困扰。我发现有些菜品的味道并不符合我的口味，而且有些服务人员的服务态度也不够热情。这些都让我感到很失望。\\n\\n最后，我还注意到有一些环境问题。例如，餐厅的卫生状况不佳，餐具和杯子经常被污染，这让我感到非常不舒服。\\n\\n我希望您能理解并采取措施来改善我们的用餐体验。我相信，只要我们共同努力，我们的服务质量将会得到显著提高。\\n\\n再次感谢您抽出宝贵的时间阅读这封信，并期待您的回复。\\n\\n顺祝商祺，\\n[你的名字]']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pure_generate = [one.split(\"assistant\\n\")[1] for one in prompt_generate]\n",
    "pure_generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8625ac0f-b45e-483a-a81c-1952e755f01e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266a37e-f30e-40aa-8690-0e7e07bf337d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04522304-6900-47bc-a8eb-0e24e2f727cc",
   "metadata": {},
   "source": [
    "## reward 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a36d8ee3-bd73-4641-af1d-0f6f1006f2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b6202b07-803d-44cf-b26e-5fca33656ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "reward_tokenizer = BertTokenizer.from_pretrained(\n",
    "    create_trained_models_path(\"Erlangshen-Roberta-330M-Sentiment\")\n",
    ")\n",
    "reward_model = BertForSequenceClassification.from_pretrained(\n",
    "    create_trained_models_path(\"Erlangshen-Roberta-330M-Sentiment\")    \n",
    ").to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a0d61015-3087-460a-9cc4-91a2b1c8ed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "## reward模型要处理上面的 pure_generate 。\n",
    "attention_mask = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "17eb9aa8-e4a8-48f9-8bcd-20236db27ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = [reward_tokenizer.encode(txt)[:512] for txt in pure_generate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "163d19f9-48b7-47d2-80a7-9bcf8322425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = max(len(i) for i in input_ids)\n",
    "## 看一下最长的长度有多长。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "23850fbf-0890-4e37-baba-c4cdf59da6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f8ebe286-bc58-419d-945a-87e25300edf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for one in input_ids:\n",
    "    padding_num = max_length - len(one)\n",
    "    res.append(one + [reward_tokenizer.pad_token_id] * padding_num)\n",
    "    attention_mask.append([1] * len(one) + [0] * padding_num)\n",
    "## 这些个大概就是说，把参差的输入补齐，用 pad_token_id 填补，然后 attention_mask 就把这些补齐的都变成0就好了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4ee3ad47-472f-4d1d-8226-1ac8827d22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = res "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a76e2d3e-2f58-4057-9abb-ce820d354177",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = reward_model(\n",
    "    torch.tensor(input_ids).to(torch.device(\"cpu\")),\n",
    "    torch.tensor(attention_mask).to(torch.device(\"cpu\"))\n",
    ")\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8dde6689-019d-4d89-a354-bb9dfdc68965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s1/1jpfx0m52rj4k7cgqkh7g3q40000gn/T/ipykernel_5544/1888170255.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  probs = torch.softmax(torch.tensor(output.logits), dim=1).tolist()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0.00012033905659336597, 0.9998795986175537]]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = torch.softmax(torch.tensor(output.logits), dim=1).tolist()\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "8fc326c3-096a-406d-bc4d-7c75fcb58d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.00012033905659336597]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward = [prob[0] for prob in probs]\n",
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453a95ff-4106-4d4f-99ae-9d3279f1174b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d0d7dde-8ffb-4941-ae66-e55bb2a4e36c",
   "metadata": {},
   "source": [
    "## 获得参考模型probs\n",
    "\n",
    "    prob_refs = self.reference_model(prompt_generate_ids, attention_mask, tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "05b03436-011a-4a0d-9169-e7649cf32333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_generate_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "083d0d99-699d-4d64-ac1b-ec69379f1f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9b7a67a3-783f-4355-b53b-a461d9853dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_ids_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "423a9f77-e01e-4049-a35c-0a4eb094d666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\n你是一个有文化的文明人<|im_end|>\\n<|im_start|>user\\n饭店服务员的态度太差，使用委婉积极的态度投诉<|im_end|>\\n<|im_start|>assistant\\n尊敬的经理：\\n\\n您好！我最近在您的饭店用餐时遇到了一些问题。我想通过这封信向您反映一下。\\n\\n首先，我对餐厅的服务态度感到非常不满。当我点菜时，服务员的态度并不友好，总是显得有些冷漠和不耐烦。他们似乎对我的需求没有足够的关注，甚至有时会对我提出一些不合理的建议或要求。\\n\\n其次，我在用餐过程中也遇到了一些困扰。我发现有些菜品的味道并不符合我的口味，而且有些服务人员的服务态度也不够热情。这些都让我感到很失望。\\n\\n最后，我还注意到有一些环境问题。例如，餐厅的卫生状况不佳，餐具和杯子经常被污染，这让我感到非常不舒服。\\n\\n我希望您能理解并采取措施来改善我们的用餐体验。我相信，只要我们共同努力，我们的服务质量将会得到显著提高。\\n\\n再次感谢您抽出宝贵的时间阅读这封信，并期待您的回复。\\n\\n顺祝商祺，\\n[你的名字]<|im_end|>']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(prompt_generate_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c9287023-bf85-4672-9a6c-9118f4f1be19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "886a9f21-6279-446d-b6dd-dcf10537b9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_model = AutoModelForCausalLM.from_pretrained(\n",
    "    create_trained_models_path(\"Qwen1.5-0.5B-Chat\"), \n",
    "    torch_dtype=\"auto\"\n",
    ")#.to(self.config.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "b233e3d2-fc5a-40cb-b513-362576072509",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = reference_model(\n",
    "    input_ids=prompt_generate_ids,\n",
    "    attention_mask=torch.Tensor(attention_mask)\n",
    ").logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8334fad8-89a4-4d4a-9564-475cd9c9d574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 151936])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1c108268-868c-4ddb-b571-c1f3d58b0259",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "3c38ccb9-9494-41ea-a1f2-77a086f9214c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 223])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate_ids[:, 1:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ff5d33a6-e0c7-41b7-85d5-c50c160824c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_refs = tools.probs_from_logits(logits[:, :-1, :], input_ids[:, 1:])\n",
    "log_probs = F.log_softmax(logits[:, :-1, :], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6487f2c9-8ba0-4032-9247-99b6dab8bc46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 223, 151936])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b896b7-8576-4479-9861-05f132c745f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## log_probs 是log_softmax后的probs。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "70a8b84c-d7e5-4aac-a8bb-153aa96239a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 223, 151936])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "268e75ea-84f7-41d9-91e2-35fa9588b44e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 223, 1])"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_generate_ids[:, 1:].unsqueeze(2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fba99b27-4377-4e93-b245-d2556a6ff781",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.gather(\n",
    "    log_probs, \n",
    "    2, \n",
    "    prompt_generate_ids[:, 1:].unsqueeze(2)\n",
    ").squeeze(-1)\n",
    "## gather的功用有点神奇。\n",
    "## probs是怎么得到的呢？大概是这样。\n",
    "### 假设 prompt_generate_ids[:, 1:].unsqueeze(2) 的【0，222，0】这个位置的值是9527，也就是这个字符的编号是9527.\n",
    "### 那么，probs里面【0，222，0】这个位置的值是：log_probs的【0，222，9527】这个位置的值。\n",
    "### 所以也就是把 log_probs 里面的，prompt_generate_ids 对应的概率取出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "255df7a3-3d99-49a1-a82f-f21dfe0ac9d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 223])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ec4810fb-b53f-4613-afc2-f38d83875b6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.5862e+01, -2.0118e+01, -1.4625e+01, -5.8781e+00, -6.7496e+00,\n",
       "         -1.0786e+01, -1.2347e+01, -4.5126e+00, -1.2683e-04, -1.0848e-05,\n",
       "         -4.2915e-06, -1.3688e+01, -9.0654e+00, -2.0585e+01, -1.2250e+01,\n",
       "         -1.3250e+01, -1.6157e+01, -3.5553e+00, -1.0188e+01, -1.6470e+01,\n",
       "         -1.1887e+01, -8.3596e-03, -1.4797e+01, -7.5138e+00, -1.7531e+01,\n",
       "         -1.0800e-04, -4.0769e-05, -1.6689e-06, -1.1878e+01, -6.6285e+00,\n",
       "         -2.3024e+00, -7.4100e-02, -2.0456e+00, -1.0352e+00, -6.2192e-01,\n",
       "         -4.9539e-01, -8.6315e-01, -1.6257e+00, -9.2592e-02, -1.4033e+00,\n",
       "         -1.4073e-01, -8.3444e-01, -1.5900e+00, -1.7716e+00, -5.4646e-02,\n",
       "         -3.6327e-01, -1.9330e+00, -2.2826e+00, -1.4088e+00, -1.8151e+00,\n",
       "         -3.9091e-02, -2.7082e-01, -1.1469e+00, -1.5173e-03, -1.1826e+00,\n",
       "         -2.6467e-01, -1.2202e+00, -7.8591e-01, -2.7405e-02, -1.9090e+00,\n",
       "         -2.4962e+00, -1.7601e-01, -2.8476e-01, -3.4755e-01, -3.0518e-01,\n",
       "         -7.7095e-01, -5.5213e-02, -3.0961e+00, -1.2720e+00, -7.7786e-01,\n",
       "         -2.7876e-01, -6.8969e-03, -1.6116e-01, -7.9984e-01, -1.7700e+00,\n",
       "         -4.7085e-01, -1.6210e-01, -2.0330e+00, -1.5543e+00, -9.9473e-01,\n",
       "         -1.5380e+00, -4.1885e-01, -7.7833e-01, -9.6232e-02, -8.8748e-04,\n",
       "         -1.4549e-01, -2.5189e+00, -1.4825e+00, -1.2611e+00, -4.3759e-01,\n",
       "         -4.1230e-01, -2.0406e+00, -2.8443e-01, -4.5444e-01, -2.0025e-01,\n",
       "         -1.9097e+00, -1.7248e+00, -2.5325e-01, -2.2977e+00, -9.7802e-01,\n",
       "         -3.3205e-01, -1.4788e+00, -1.5401e+00, -4.1428e-01, -3.0959e+00,\n",
       "         -8.8127e-01, -7.9957e-01, -3.4938e-02, -7.8769e-03, -1.5778e+00,\n",
       "         -1.9053e-01, -5.0135e-01, -2.0051e+00, -1.1185e-01, -4.9050e-02,\n",
       "         -2.0708e+00, -1.7214e-02, -2.2757e+00, -1.2587e+00, -6.9210e-01,\n",
       "         -1.6218e+00, -1.1337e+00, -6.6549e-01, -4.3905e-01, -4.8110e-01,\n",
       "         -7.8424e-02, -1.4332e+00, -9.0584e-01, -2.2391e+00, -2.4339e+00,\n",
       "         -1.6328e+00, -6.6577e-02, -1.4301e+00, -3.4319e-01, -9.6519e-01,\n",
       "         -2.5866e-01, -1.9109e+00, -1.3696e-01, -2.5146e-01, -1.1924e-01,\n",
       "         -2.0951e+00, -9.3673e-01, -3.7669e-01, -6.5390e-01, -3.4467e-03,\n",
       "         -2.2341e+00, -8.5067e-01, -2.7803e+00, -2.0477e+00, -3.4970e-01,\n",
       "         -2.8657e-01, -2.2059e+00, -8.1739e-02, -1.0333e+00, -1.6102e-01,\n",
       "         -1.3631e+00, -2.1965e-01, -2.3718e+00, -6.1449e-03, -2.1497e+00,\n",
       "         -9.4084e-01, -2.4182e+00, -2.3430e+00, -1.3339e+00, -2.2764e+00,\n",
       "         -3.7046e-01, -6.5652e-01, -4.1866e-01, -3.6378e-01, -7.2532e-01,\n",
       "         -9.4048e-01, -2.6844e-01, -1.4968e+00, -1.5650e-01, -2.7019e-01,\n",
       "         -1.8985e+00, -2.1951e+00, -1.4078e+00, -1.2810e+00, -3.6533e-01,\n",
       "         -5.1441e-01, -1.9513e+00, -1.6555e-01, -3.4990e-01, -3.6269e-02,\n",
       "         -1.4088e+00, -2.9640e-01, -5.7377e-01, -2.2965e-01, -6.4307e-01,\n",
       "         -1.8040e-03, -7.7226e-01, -2.0412e+00, -1.9051e+00, -3.7842e-01,\n",
       "         -1.1132e+00, -1.1079e+00, -3.1117e-01, -1.1267e+00, -2.4572e-01,\n",
       "         -6.9444e-01, -5.6862e-01, -5.3619e-01, -2.7202e-02, -3.4045e-01,\n",
       "         -2.6603e-01, -4.0531e-06, -2.9816e-02, -1.9439e+00, -9.4139e-01,\n",
       "         -1.7653e-01, -8.4353e-02, -1.5398e-01, -8.8315e-01, -3.4928e-05,\n",
       "         -1.8835e-05, -5.2452e-06, -8.1457e-01, -2.0805e-02, -8.9950e-01,\n",
       "         -7.2363e-03, -5.1607e-02, -7.4145e-04]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "af0333ad-5a47-476a-80b6-6c1438dc3415",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_ids.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "ac937e54-50dd-4e31-9fc8-d8fca24da2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prob_refs = tools.filter_mask(prob_refs)\n",
    "values = probs\n",
    "## 相当于每一个字符id对应的“某种概率”的值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "f346e1d8-4167-4fb8-bd79-85ca0c96f8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 223])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "e3d0ffe8-a829-4d9c-b4ab-d02eb56c657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_refs = [\n",
    "    value[-(generate_ids.shape[1] - 1):][one_response_ids_mask]\\\n",
    "    for value, one_response_ids_mask in zip(values, generate_ids_mask)\n",
    "]\n",
    "## 相当于是啥呢，就是说ha\n",
    "## 把value里面纯回答部分的概率值给他切出来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "41584e88-2c5d-4cbe-a0a8-d901820d95b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for value, one_response_ids_mask in zip(values, generate_ids_mask):\n",
    "#     break\n",
    "\n",
    "# value.shape\n",
    "\n",
    "# one_response_ids_mask\n",
    "\n",
    "# -(generate_ids.shape[1] - 1)\n",
    "\n",
    "# value[-(generate_ids.shape[1] - 1):]\n",
    "\n",
    "# value[-(generate_ids.shape[1] - 1):][one_response_ids_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "78965374-f8a3-4f88-8780-6f9ba54b9809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prob_refs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9459f7-51f7-49da-b955-abdc79914eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "【ckpt】\n",
    "## 我还想理解理解，为什么会有generate和forward之别。我想搞懂他。下一步就搞懂他。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "53009b45-f47c-4c83-846c-5ea0107dcf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\n你是一个有文化的文明人<|im_end|>\\n<|im_start|>user\\n饭店服务员的态度太差，使用委婉积极的态度投诉<|im_end|>\\n<|im_start|>assistant\\n尊敬的经理：\\n\\n您好！我最近在您的饭店用餐时遇到了一些问题。我想通过这封信向您反映一下。\\n\\n首先，我对餐厅的服务态度感到非常不满。当我点菜时，服务员的态度并不友好，总是显得有些冷漠和不耐烦。他们似乎对我的需求没有足够的关注，甚至有时会对我提出一些不合理的建议或要求。\\n\\n其次，我在用餐过程中也遇到了一些困扰。我发现有些菜品的味道并不符合我的口味，而且有些服务人员的服务态度也不够热情。这些都让我感到很失望。\\n\\n最后，我还注意到有一些环境问题。例如，餐厅的卫生状况不佳，餐具和杯子经常被污染，这让我感到非常不舒服。\\n\\n我希望您能理解并采取措施来改善我们的用餐体验。我相信，只要我们共同努力，我们的服务质量将会得到显著提高。\\n\\n再次感谢您抽出宝贵的时间阅读这封信，并期待您的回复。\\n\\n顺祝商祺，\\n[你的名字]<|im_end|>']"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids = lora_model.generate(model_inputs.input_ids, max_new_tokens=512, top_p=1.0,\n",
    "                                            num_beams=1,\n",
    "                                            do_sample=False)\n",
    "tokenizer.batch_decode(generated_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0a078ca5-695a-49bd-bdd2-47231241633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hhd = reference_model(model_inputs.input_ids, model_inputs.attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "46ef7ca2-8159-4a2d-b817-c903410354b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|im_start|>system\\n你是一个有文化的文明人<|im_end|>\\n<|im_start|>user\\n饭店服务员的态度太差，使用委婉积极的态度投诉<|im_end|>\\n<|im_start|>assistant\\n']"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(\n",
    "    model_inputs.input_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "0d126c9a-a9eb-48ce-a711-864bc0b2bead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 31, 151936])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hhd.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "eea7581e-0731-4223-886f-09be54cc381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_probs = F.log_softmax(hhd.logits[:, :, :], dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "5f9bca0d-f6f9-4f8b-a2e5-54888d0f4d6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.mybatis',\n",
       " '事业单位',\n",
       " '<|im_start|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '\\n',\n",
       " '<|im_start|>',\n",
       " '是',\n",
       " '<|im_end|>',\n",
       " '<|im_start|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '婉',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '<|im_end|>',\n",
       " '\\n',\n",
       " '<|im_start|>',\n",
       " '如果你',\n",
       " '尊敬',\n",
       " '尊敬']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(\n",
    "    torch.argmax(hhd.logits, dim=2)[0]    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d0e2d80-c504-4d12-a5f3-89cec9a6d7a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0f19d5-f6e2-4f7a-9e81-f0b9f1cd0e07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff03fee0-45e2-4aad-a7fb-1faefe112885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce91d29-ecd0-4cd6-8829-3c5e8bda58f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0fa2f8-af27-4faa-8447-4c6550cd4670",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ff4a36-a87b-41f4-a09e-0b8de62096bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c8d49c2-a8ee-40b3-9c56-7fba0925e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7205dd34-66bd-4823-bfba-40e0bb971774",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# (之前的草稿)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "430c7872-c344-4dd4-9d20-fc4bdc19841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载acm的tokenizer，\n",
    "## 加载一下数据试试看。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1471894-af16-4718-83a6-80d0ab00d7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(create_trained_models_path(\"Qwen1.5-0.5B-Chat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e77b9689-ee3d-433b-8322-a32b5b2db2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qwen2TokenizerFast(name_or_path='/Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO/trained_models/Qwen1.5-0.5B-Chat', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
       "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5817fc71-7d6c-47c5-9c87-59961f135c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 加载一下数据：\n",
    "with open(\n",
    "    \"/Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/RLHF_PPO/data/train_data.json\", \n",
    "    'r', \n",
    "    encoding=\"utf-8\"\n",
    ") as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76d98d2e-1e23-4f6d-aa5e-84293e187afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'query': '饭店服务员的态度太差，使用委婉积极的态度投诉', 'system_content': '你是一个有文化的文明人'},\n",
       " {'query': '领导故意刁难你，你想骂他娘的，使用文明语言骂他娘的', 'system_content': '你是一个有文化的文明人'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data\n",
    "## 数据大概长这样。有一个query，有一个system_content。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d09ad7f-b98b-418e-9ba6-84fcc67e05b7",
   "metadata": {},
   "source": [
    "# 尝试一下呗。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2d6ca0f-3c8a-48a6-b361-fb94d633c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60a4d000-e624-4e70-8cdc-d4a5810c83bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a63b18a-9fd0-4cd0-b042-531bd2f9b8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, PeftModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992954af-a75c-403f-8e19-b3c9d07ad28a",
   "metadata": {},
   "source": [
    "# 初始化一个演员·评论员模型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5c153e-79da-4377-86e4-95ded1100a80",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75a5d31-b49a-42e2-b6dd-3609d3b09baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c792794d-dcce-4c3d-9c67-54640a630d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bc604ee-7acd-453f-befd-2ef2497d254d",
   "metadata": {},
   "source": [
    "## 演员·评论员"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aef0609b-1950-434d-ab79-0b9565d58d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 尝试初始化一下原始的文本生成模型.\n",
    "## 这个模型是一个生成模型哦。\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    create_trained_models_path(\"Qwen1.5-0.5B-Chat\")\n",
    ").to(\"cpu\").eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7449b969-1961-4007-ac61-419dbdb6503e",
   "metadata": {},
   "source": [
    "## Lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc5d58a9-85b1-45f5-a213-49690bd24de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8947351e-1e19-4b61-bca4-ace5a222ddb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=2, ## 把秩降到这个数。\n",
    "    lora_alpha=8, ## 这个是一个扩张系数。\n",
    "    target_modules=['k_proj',  'v_proj'],\n",
    "    lora_dropout=0,\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e2169070-311b-4474-a3e2-09899d26db44",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_model = PeftModel(model, lora_config)\n",
    "v_head = torch.nn.Linear(1024, 1, bias=False).to(\"cpu\")\n",
    "for name, module in lora_model.named_modules():\n",
    "    if 'lora_' in name:\n",
    "        for param in module.parameters():\n",
    "            param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c0636-68b7-4cbe-9075-34eb2c7da423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lora_forward(input_ids, attention_mask, tools):\n",
    "    res = lora_model.forward(input_ids, attention_mask, output_hidden_states=True)\n",
    "    values = v_head(res.hidden_states[0]).squeeze(-1)[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905d2743-2a77-49f6-90cb-4e05c0f62d1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d99c835-04c7-4e7b-b59f-dfb78b751ab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9beff56-f8d8-44cd-a37c-8c856c8cd969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f4dec4-fe9f-45a9-bf66-c0dd17f78c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c5ac75-0f6b-46d4-978e-689a456d39d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1a868-ef5c-4409-bc05-0e834b7027c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e257aad-66aa-447e-a6d0-91a5bd906279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cab4fce-465f-4abd-af4e-1e13e3a6b625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e9c894-df54-48c8-8ac6-ef6a7d7ec73d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c180e2-31f5-420c-a872-53afbca247fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cadcf71c-6c2b-40ce-988a-bb3189085160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666e359e-f854-4060-a903-d6039f6015ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers.models.llama.modeling_llama import LlamaForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122b5f0a-0eb8-4605-b4cf-68c96f70b756",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaRewardModel(LlamaForCausalLM):\n",
    "    \n",
    "    def __init__(self, config, opt, tokenizer):\n",
    "        super().__init__(config)\n",
    "        self.opt = opt\n",
    "        self.tokenizer = tokenizer\n",
    "        self.reward_head = torch.nn.Linear(config.hidden_size, 1, bias=False)\n",
    "        \n",
    "    def forward(self, decoder_input, only_last=True):\n",
    "        attention_mask = decoder_input.ne(self.tokenizer.pad_token_id)\n",
    "        output = self.model.forward( ## 【TODO】这里面有一个model，是个啥？\n",
    "            input_ids=decoder_input,\n",
    "            attention_mask=attention_mask,\n",
    "            return_dict=True,\n",
    "            use_cache=False\n",
    "        )\n",
    "        if only_last:\n",
    "            logits = self.reward_head(output.last_hidden_state[:, -1, :]).squeeze(-1)\n",
    "        else:\n",
    "            logits = self.reward_head(output.last_hidden_state).squeeze(-1)\n",
    "        return (logits,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c5c0c9-e8f1-4d45-9ece-9c058180f470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c576b6-7672-4ed5-8d62-48cfe2c7643c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 奖励模型训练损失代码，不仅需要拉大奖励模型在 chosen 和 rejected 回复分数上的差距，\n",
    "# 也可以将在 chosen 数据上的生成损失加入到最终的优化目标中。\n",
    "import torch\n",
    "def _criterion(self, model_output, batch, return_output):\n",
    "    logits, predict_label, *outputs = model_output\n",
    "    bs = logits.size(0) // 2\n",
    "    \n",
    "    preferred_rewards = logits[:bs]\n",
    "    rejected_rewards = logits[bs:]\n",
    "    \n",
    "    probs = torch.sigmoid(preferred_rewards - rejected_rewards)\n",
    "    print(f\"self.train_state:{self.train_state}, predict_label:{predict_label}\")\n",
    "    loss = (-torch.log(probs + 1e-5)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7341976-7599-474c-a967-98152a04d484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

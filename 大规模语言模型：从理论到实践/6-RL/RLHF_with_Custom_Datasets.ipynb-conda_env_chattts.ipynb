{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "875b94f3-440b-44f2-bfcf-bc889b46d02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "storage dir: /Users/minkexiu/Downloads/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/6-RL\n",
      "code dir: /Users/minkexiu/Documents/GitHub/ML_runCodeFromBook/大规模语言模型：从理论到实践/6-RL\n"
     ]
    }
   ],
   "source": [
    "import random, os, tqdm, time, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../../../\")\n",
    "\n",
    "random.seed(618)\n",
    "np.random.seed(907)\n",
    "\n",
    "new_base_path = os.path.join(\n",
    "    \"/Users/minkexiu/Downloads/\",\n",
    "    \"/\".join(\n",
    "        os.getcwd().split(\"/\")[-1*(len(sys.path[-1].split(\"/\")) - 1):]\n",
    "    ),\n",
    ")\n",
    "print(\"storage dir:\", new_base_path)\n",
    "print(\"code dir:\", os.getcwd())\n",
    "\n",
    "## 创建文件夹。\n",
    "if not os.path.exists(new_base_path):\n",
    "    os.makedirs(\n",
    "        new_base_path\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"preprocessedData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"preprocessedData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"originalData\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"originalData\")\n",
    "    )\n",
    "if not os.path.exists(os.path.join(new_base_path, \"trained_models\")):\n",
    "    os.makedirs(\n",
    "        os.path.join(new_base_path, \"trained_models\")\n",
    "    )\n",
    "\n",
    "def create_originalData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"originalData\", filename_or_path)\n",
    "def create_preprocessedData_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"preprocessedData\", filename_or_path)\n",
    "def create_trained_models_path(filename_or_path):\n",
    "    return os.path.join(new_base_path, \"trained_models\", filename_or_path)\n",
    "\n",
    "def millisec2datetime(timestamp):\n",
    "    time_local = time.localtime(timestamp/1000)\n",
    "    return time.strftime(\"%Y-%m-%d %H:%M:%S\", time_local)\n",
    "    \n",
    "def run_finish():\n",
    "    # 假设你的字体文件是 'myfont.ttf' 并且位于当前目录下  \n",
    "    font = FontProperties(fname=\"/Users/minkexiu/Documents/GitHub/ML_Tryout/SimHei.ttf\", size=24)  \n",
    "    # 创建一个空白的图形  \n",
    "    fig, ax = plt.subplots()  \n",
    "    ax.imshow(\n",
    "        plt.imread(\"/Users/minkexiu/Downloads/wallhaven-dgxpyg.jpg\")\n",
    "    )\n",
    "    # 在图形中添加文字  \n",
    "    ax.text(\n",
    "        ax.get_xlim()[1] * 0.5, \n",
    "        ax.get_ylim()[0] * 0.5, \n",
    "        f\"程序于这个点跑完：\\n{millisec2datetime(time.time()*1000)}\", fontproperties=font, ha=\"center\", va=\"center\", color=\"red\"\n",
    "    )  \n",
    "    # 设置图形的布局  \n",
    "    # ax.set_xlim(0, 1)  \n",
    "    # ax.set_ylim(0, 1)  \n",
    "    ax.set_xticks([])  \n",
    "    ax.set_yticks([])  \n",
    "    ax.patch.set_color(\"blue\")\n",
    "    # 显示图形  \n",
    "    plt.show()\n",
    "        \n",
    "tqdm.tqdm.pandas() ## 引入这个，就可以在apply的时候用progress_apply了。\n",
    "\n",
    "import IPython\n",
    "def kill_current_kernel():\n",
    "    '''杀死当前的kernel释放内存空间。'''\n",
    "    IPython.Application.instance().kernel.do_shutdown(True) \n",
    "    \n",
    "def simply_show_data(df1):\n",
    "    print(df1.shape)\n",
    "    display(df1.head())\n",
    "    \n",
    "def wait_flag(saved_flag_path, time_interval_sec=10):\n",
    "    print(\"waiting for\", saved_flag_path)\n",
    "    time_count = 0\n",
    "    while True:\n",
    "        if os.path.exists(saved_flag_path):\n",
    "            break\n",
    "        time.sleep(time_interval_sec)\n",
    "        time_count+=time_interval_sec\n",
    "        print(time_count, end=\" \")\n",
    "    print(\"finish!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015a0bba-b3d7-49f3-bb13-85c90aef93b1",
   "metadata": {},
   "source": [
    "https://github.com/HumanSignal/RLHF/blob/master/tutorials/RLHF_with_Custom_Datasets.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef75c47-fba2-499b-aca8-0fbac52f64eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, set_seed\n",
    "import json\n",
    "\n",
    "def generate_examples(prompt_list, model_name='gpt2', max_length=50, num_return_sequences=2, seed=42):\n",
    "    generator = pipeline('text-generation', model=model_name, device=0)\n",
    "    set_seed(seed)\n",
    "    examples = []\n",
    "    for prompt in prompt_list:\n",
    "        result = generator(prompt, max_length=max_length, num_return_sequences=num_return_sequences)\n",
    "        example = {'prompt': prompt}\n",
    "        for i, res in enumerate(result):\n",
    "            answer = res['generated_text'].lstrip().removeprefix(prompt).strip()\n",
    "            example[f'answer{i + 1}'] = answer\n",
    "        examples.append(example)\n",
    "        print(json.dumps(example, indent=2))\n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a829c461-51e1-4f65-a236-cad5bc66dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What is the latest news on the stock market?\",\n",
    "    \"What is the current state of the economy?\",\n",
    "    \"What are the latest developments in technology?\",\n",
    "    \"What is the political situation in the Middle East?\",\n",
    "    \"What are the latest trends in fashion and beauty?\",\n",
    "    \"What are the top travel destinations for this year?\",\n",
    "    \"What are some healthy recipes for a vegan diet?\",\n",
    "    \"What are the most important events happening in the world today?\",\n",
    "    \"What are some tips for improving mental health?\",\n",
    "    \"What are the best ways to save money for retirement?\",\n",
    "    \"What are some popular new books or movies?\",\n",
    "    \"What are some effective ways to reduce stress?\",\n",
    "    \"What are the latest developments in artificial intelligence?\",\n",
    "    \"What are some top-rated restaurants in your city?\",\n",
    "    \"What are the best ways to stay fit and healthy?\",\n",
    "    \"What are some tips for successful entrepreneurship?\",\n",
    "    \"What are some effective ways to improve productivity?\",\n",
    "    \"What are the latest developments in climate change research?\",\n",
    "    \"What are some top-rated TV shows or movies on streaming services?\",\n",
    "    \"What are some fun activities to do on weekends?\",\n",
    "    \"What are some effective ways to manage time and prioritize tasks?\",\n",
    "    \"What are the latest trends in home decor and design?\",\n",
    "    \"What are the best ways to develop a successful career?\",\n",
    "    \"What are some popular new products or gadgets?\",\n",
    "    \"What are some effective ways to improve communication skills?\",\n",
    "    \"What are some tips for successful relationships?\",\n",
    "    \"What are the latest developments in space exploration?\",\n",
    "    \"What are some top-rated online courses or certifications?\",\n",
    "    \"What are some effective ways to improve public speaking skills?\",\n",
    "    \"What are the latest trends in digital marketing?\",\n",
    "    \"What are some fun and creative DIY projects?\",\n",
    "    \"What are some effective ways to improve leadership skills?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390b87d-799d-4a17-b741-dbdb9f7717ef",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "generated_examples = generate_examples(prompts)\n",
    "\n",
    "# Save generated examples to import in Label Studio\n",
    "with open('ls_input_data.json', 'w') as f:\n",
    "    json.dump(generated_examples, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee84f0f-2354-4cca-b02e-6bc9fe66213b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "134217728/1024**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e52f8bb1-2808-4f48-bdd5-8eba31e7d602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "24576/1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e63b0c6-542f-48a0-9b7d-4e0c666abd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "134217728\n",
    "25165824"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f3c2e-cce7-4a3c-b206-206fbff80d31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b73a16-1a72-4f06-81bd-1aebab9f7158",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "839096b3-2b71-470d-8baa-7b69709f0fcd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "# This file is generated by Label Studio after completing annotations\n",
    "data_path = 'ls_export_data.json'\n",
    "\n",
    "with codecs.open(data_path, 'r', encoding='utf-8') as f:\n",
    "      data = json.load(f)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "889be972-0cde-4164-a888-a7b1c57986a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'reward_model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dataset\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreward_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPTRewardModel\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'reward_model'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from reward_model import GPTRewardModel\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "def create_comparison_dataset_ls(path: str):\n",
    "    with codecs.open(data_path, 'r', encoding='utf-8') as f:\n",
    "          data = json.load(f)\n",
    "    pairs = []\n",
    "    for sample in data:\n",
    "        chosen = None\n",
    "        rejected = None\n",
    "        for annotation in sample['annotations']:\n",
    "            if annotation['result'][0]['value']['selected'] == 'left':\n",
    "                chosen = sample['data']['prompt'] + '\\n' + sample['data']['answer1']\n",
    "                rejected = sample['data']['prompt'] + '\\n' + sample['data']['answer2']\n",
    "            else:\n",
    "                chosen = sample['data']['prompt'] + '\\n' + sample['data']['answer2']\n",
    "                rejected = sample['data']['prompt'] + '\\n' + sample['data']['answer1']\n",
    "            pair = {\n",
    "                'chosen': chosen,\n",
    "                'rejected': rejected\n",
    "            }\n",
    "            pairs.append(pair)\n",
    "    return pairs\n",
    "\n",
    "class PairwiseDataset(Dataset):\n",
    "    def __init__(self, pairs, tokenizer, max_length):\n",
    "        self.chosen_input_ids = []\n",
    "        self.chosen_attn_masks = []\n",
    "        self.rejected_input_ids = []\n",
    "        self.rejected_attn_masks = []\n",
    "        for pair in tqdm(pairs):\n",
    "            chosen, rejected = pair[\"chosen\"], pair[\"rejected\"]\n",
    "            chosen_encodings_dict = tokenizer(\n",
    "                \"<|startoftext|>\" + chosen + \"<|endoftext|>\",\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            rejected_encodings_dict = tokenizer(\n",
    "                \"<|startoftext|>\" + rejected + \"<|endoftext|>\",\n",
    "                truncation=True,\n",
    "                max_length=max_length,\n",
    "                padding=\"max_length\",\n",
    "                return_tensors=\"pt\",\n",
    "            )\n",
    "            self.chosen_input_ids.append(chosen_encodings_dict[\"input_ids\"])\n",
    "            self.chosen_attn_masks.append(chosen_encodings_dict[\"attention_mask\"])\n",
    "            self.rejected_input_ids.append(rejected_encodings_dict[\"input_ids\"])\n",
    "            self.rejected_attn_masks.append(rejected_encodings_dict[\"attention_mask\"])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.chosen_input_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (\n",
    "            self.chosen_input_ids[idx],\n",
    "            self.chosen_attn_masks[idx],\n",
    "            self.rejected_input_ids[idx],\n",
    "            self.rejected_attn_masks[idx],\n",
    "        )\n",
    "\n",
    "\n",
    "class DataCollatorReward:\n",
    "    def __call__(self, data):\n",
    "        batch = {}\n",
    "        batch[\"input_ids\"] = torch.cat([f[0] for f in data] + [f[2] for f in data])\n",
    "        batch[\"attention_mask\"] = torch.cat([f[1] for f in data] + [f[3] for f in data])\n",
    "        batch[\"labels\"] = torch.tensor([0] * len(data) + [1] * len(data))\n",
    "        return batch\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    chosen_end_scores = eval_preds.predictions[0]  # chosen scores\n",
    "    rejected_end_scores = eval_preds.predictions[1]  # rejected scores\n",
    "\n",
    "    result = {}\n",
    "    acc = sum(chosen_end_scores > rejected_end_scores) / len(rejected_end_scores)\n",
    "    result[\"accuracy\"] = acc\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1c01db-365c-455d-b6e2-7dcdf9b558e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "if not os.path.exists(\"rm_checkpoint\"):\n",
    "    os.mkdir(\"rm_checkpoint\")\n",
    "\n",
    "# Initialize the reward model from the GPT-2 model (optionally SFT GPT-2)\n",
    "model = GPTRewardModel(\"gpt2\")\n",
    "\n",
    "# Freeze the first 70% of the hidden layers of the reward model backbone\n",
    "layers = model.transformer.h\n",
    "num_layers = len(layers)\n",
    "num_unfrozen = int(0.3 * num_layers)\n",
    "for layer in layers[:-num_unfrozen]:\n",
    "    layer.requires_grad_(False)\n",
    "\n",
    "# Create the comparisons datasets\n",
    "pairs = create_comparison_dataset_ls(data_path)\n",
    "train_size = int(0.8 * len(pairs))  # 80% training, 20% validation\n",
    "train_pairs = pairs[0:train_size]\n",
    "val_pairs = pairs[train_size:]\n",
    "\n",
    "\n",
    "# Make pairwise datasets for training\n",
    "max_length = 550\n",
    "train_dataset = PairwiseDataset(train_pairs, tokenizer, max_length=max_length)\n",
    "val_dataset = PairwiseDataset(val_pairs, tokenizer, max_length=max_length)\n",
    "\n",
    "# Create the collator to gather batches of pairwise comparisons\n",
    "data_collator = DataCollatorReward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dadea2c-09d0-4c9d-a668-f4721c4f1445",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"rm_checkpoint/\",\n",
    "    num_train_epochs=50,\n",
    "    logging_steps=10,\n",
    "    gradient_accumulation_steps=4,\n",
    "    save_strategy=\"steps\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    eval_accumulation_steps=1,\n",
    "    eval_steps=10,\n",
    "    save_steps=10,\n",
    "    warmup_steps=100,\n",
    "    logging_dir=\"./logs\",\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    learning_rate=1e-5,\n",
    "    # deepspeed=\"ds_config_gpt_j.json\",\n",
    "    save_total_limit=1\n",
    ")\n",
    "\n",
    "Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=data_collator,\n",
    ").train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
